{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images from category: spidermite and subfolder: Tomato__spidermite\n",
      "Loading images from category: bacterialspot and subfolder: Tomato___Bacterialspot\n",
      "Loading images from category: earlyblight and subfolder: Tomato___Earlyblight\n",
      "Loading images from category: healthy and subfolder: Tomato___healthy\n",
      "Loading images from category: lateblight and subfolder: Tomato___Lateblight\n",
      "Loading images from category: leafmold and subfolder: Tomato___Leafmold\n",
      "Loading images from category: septorialeafspot and subfolder: Tomato___Septorialeafspot\n",
      "Loading images from category: targetspot and subfolder: Tomato___Targetspot\n",
      "Loading images from category: mosaicvirus and subfolder: Tomato___Tomato_mosaicvirus\n",
      "Loading images from category: yellowleafcurlvirus and subfolder: Tomato___Tomato_yellowleafcurlvirus\n",
      "Loading images from category: bacterialspot and subfolder: Tomato___Bacterialspot\n",
      "Loading images from category: earlyblight and subfolder: Tomato___Earlyblight\n",
      "Loading images from category: healthy and subfolder: Tomato___healthy\n",
      "Loading images from category: lateblight and subfolder: Tomato___Lateblight\n",
      "Loading images from category: leafmold and subfolder: Tomato___Leafmold\n",
      "Loading images from category: septorialeafspot and subfolder: Tomato___Septorialeafspot\n",
      "Loading images from category: spidermite and subfolder: Tomato___Spider_spidermite\n",
      "Loading images from category: targetspot and subfolder: Tomato___Targetspot\n",
      "Loading images from category: mosaicvirus and subfolder: Tomato___Tomato_mosaicvirus\n",
      "Loading images from category: yellowleafcurlvirus and subfolder: Tomato___Tomato_Yellowleafcurlvirus\n",
      "Loading images from category: bacterialspot and subfolder: tomato_bacterialspot\n",
      "Loading images from category: earlyblight and subfolder: tomato_earlyblight\n",
      "Loading images from category: healthy and subfolder: tomato_healthy\n",
      "Loading images from category: lateblight and subfolder: tomato_lateblight\n",
      "Loading images from category: leafmold and subfolder: tomato_leafmold\n",
      "Loading images from category: mosaicvirus and subfolder: tomato_mosaicvirus\n",
      "Loading images from category: septorialeafspot and subfolder: tomato_Septorialeafspot\n",
      "Loading images from category: spidermite and subfolder: tomato_spidermite\n",
      "Loading images from category: targetspot and subfolder: tomato_targetspot\n",
      "Loading images from category: yellowleafcurlvirus and subfolder: tomato_yellowleafcurlvirus\n",
      "Images loaded successfully\n",
      "Total de imagens no conjunto de treino: 15000\n",
      "Total de imagens no conjunto de validação: 4000\n",
      "Total de imagens no conjunto de teste: 1000\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "\n",
    "from utils.duarte_utils import DuarteUtils\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_dir = \"..\\isec-ic\\\\dataset\\\\train\"\n",
    "validation_dir = \"..\\isec-ic\\\\dataset\\\\valid\"\n",
    "test_dir = \"..\\isec-ic\\\\dataset\\\\test\"\n",
    "\n",
    "current_dir = os.path.dirname(os.path.realpath(__file__ if '__file__' in locals() else os.getcwd()))\n",
    "train_dir = os.path.join(current_dir, train_dir)\n",
    "validation_dir = os.path.join(current_dir, validation_dir)\n",
    "test_dir = os.path.join(current_dir, test_dir)\n",
    "#categories = [\"bacterialspot\", \"healthy\",\"lateblight\",\"leafmold\", \"mosaicvirus\",\"yellowleafcurlvirus\" ,\"spidermite\",\"septorialeafspot\"]\n",
    "categories = [\"bacterialspot\", \"healthy\",\"lateblight\",\"leafmold\", \"mosaicvirus\",\"yellowleafcurlvirus\" ,\"spidermite\",\"septorialeafspot\", \"earlyblight\",  \"targetspot\"]\n",
    "\n",
    "def load_images_from_folder(folder):\n",
    "    images = []\n",
    "    labels = []\n",
    "    subfolders = os.listdir(folder)\n",
    "    for subfolder in subfolders:\n",
    "        category = subfolder.split(\"_\")[-1].lower()\n",
    "        if category in categories:\n",
    "            print(\"Loading images from category: \" + category + \" and subfolder: \" + subfolder)\n",
    "            subfolder_path = os.path.join(folder, subfolder)\n",
    "            for filename in os.listdir(subfolder_path):\n",
    "                img = Image.open(os.path.join(subfolder_path, filename))\n",
    "                img = img.resize((64, 64))\n",
    "                img = np.array(img) / 255.0\n",
    "                images.append(img)\n",
    "                labels.append(categories.index(category))\n",
    "        else:\n",
    "            print(\"Category: \" + category + \" from subfolder \" + subfolder + \" is not in the list of categories.\")\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "x_train, y_train = load_images_from_folder(train_dir)\n",
    "x_validation, y_validation = load_images_from_folder(validation_dir)\n",
    "x_test, y_test = load_images_from_folder(test_dir)\n",
    "\n",
    "print(\"Images loaded successfully\")\n",
    "\n",
    "print(f\"Total de imagens no conjunto de treino: {x_train.shape[0]}\")\n",
    "print(f\"Total de imagens no conjunto de validação: {x_validation.shape[0]}\")\n",
    "print(f\"Total de imagens no conjunto de teste: {x_test.shape[0]}\")\n",
    "\n",
    "DuarteUtils.display_folder_distributions(y_train, y_validation, y_test, categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, BatchNormalization\n",
    "\n",
    "def create_cnn_model(dropout_rate, learning_rate):\n",
    "    base_model = VGG16(weights='imagenet', include_top=False, input_shape=(64, 64, 3))\n",
    "\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Tornar as últimas n camadas treináveis\n",
    "    n_trainable_layers = 3\n",
    "    for layer in base_model.layers[-n_trainable_layers:]:\n",
    "        layer.trainable = True\n",
    "        \n",
    "    x = base_model.output\n",
    "    x = Flatten()(x) \n",
    "    x = Dense(128, activation='relu')(x)  \n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    predictions = Dense(len(categories), activation='softmax')(x)  # Output layer\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treinando o modelo...\n",
      "Epoch 1/60\n",
      "375/375 [==============================] - 4s 8ms/step - loss: 0.7734 - accuracy: 0.7482 - val_loss: 0.5938 - val_accuracy: 0.8034\n",
      "Epoch 2/60\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.2928 - accuracy: 0.9085 - val_loss: 0.4548 - val_accuracy: 0.8434\n",
      "Epoch 3/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.2011 - accuracy: 0.9325 - val_loss: 0.8840 - val_accuracy: 0.7497\n",
      "Epoch 4/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.1476 - accuracy: 0.9538 - val_loss: 0.6161 - val_accuracy: 0.8303\n",
      "Epoch 5/60\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 0.1209 - accuracy: 0.9598 - val_loss: 0.6873 - val_accuracy: 0.8112\n",
      "Epoch 6/60\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 0.1042 - accuracy: 0.9684 - val_loss: 0.3701 - val_accuracy: 0.8922\n",
      "Epoch 7/60\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 0.0881 - accuracy: 0.9709 - val_loss: 0.1635 - val_accuracy: 0.9431\n",
      "Epoch 8/60\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 0.0591 - accuracy: 0.9847 - val_loss: 0.2921 - val_accuracy: 0.9172\n",
      "Epoch 9/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0576 - accuracy: 0.9825 - val_loss: 0.2904 - val_accuracy: 0.9156\n",
      "Epoch 10/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0528 - accuracy: 0.9837 - val_loss: 0.1812 - val_accuracy: 0.9413\n",
      "Epoch 11/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0440 - accuracy: 0.9859 - val_loss: 0.3225 - val_accuracy: 0.9122\n",
      "Epoch 12/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0419 - accuracy: 0.9852 - val_loss: 0.7560 - val_accuracy: 0.8306\n",
      "Epoch 13/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0476 - accuracy: 0.9846 - val_loss: 0.2215 - val_accuracy: 0.9381\n",
      "Epoch 14/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0309 - accuracy: 0.9903 - val_loss: 0.1919 - val_accuracy: 0.9466\n",
      "Epoch 15/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0224 - accuracy: 0.9936 - val_loss: 0.2381 - val_accuracy: 0.9316\n",
      "Epoch 16/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0219 - accuracy: 0.9925 - val_loss: 0.1725 - val_accuracy: 0.9497\n",
      "Epoch 17/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0245 - accuracy: 0.9913 - val_loss: 0.2442 - val_accuracy: 0.9372\n",
      "Epoch 18/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0174 - accuracy: 0.9945 - val_loss: 0.1982 - val_accuracy: 0.9453\n",
      "Epoch 19/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0291 - accuracy: 0.9903 - val_loss: 0.2919 - val_accuracy: 0.9266\n",
      "Epoch 20/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0359 - accuracy: 0.9896 - val_loss: 0.3527 - val_accuracy: 0.9241\n",
      "Epoch 21/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0165 - accuracy: 0.9945 - val_loss: 0.1935 - val_accuracy: 0.9506\n",
      "Epoch 22/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0238 - accuracy: 0.9908 - val_loss: 0.1936 - val_accuracy: 0.9519\n",
      "Epoch 23/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0203 - accuracy: 0.9925 - val_loss: 0.2064 - val_accuracy: 0.9484\n",
      "Epoch 24/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0101 - accuracy: 0.9961 - val_loss: 0.1988 - val_accuracy: 0.9531\n",
      "Epoch 25/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0211 - accuracy: 0.9935 - val_loss: 0.2364 - val_accuracy: 0.9403\n",
      "Epoch 26/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0202 - accuracy: 0.9943 - val_loss: 0.2681 - val_accuracy: 0.9350\n",
      "Epoch 27/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0101 - accuracy: 0.9970 - val_loss: 0.1851 - val_accuracy: 0.9525\n",
      "Epoch 00027: early stopping\n",
      "Melhor Accuracy de Treino:  0.9972500205039978\n",
      "Melhor Accuracy de Validação:  0.953125\n",
      "Treinando o modelo...\n",
      "Epoch 1/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.7903 - accuracy: 0.7412 - val_loss: 0.5061 - val_accuracy: 0.8181\n",
      "Epoch 2/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.2759 - accuracy: 0.9123 - val_loss: 0.3954 - val_accuracy: 0.8616\n",
      "Epoch 3/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.2029 - accuracy: 0.9354 - val_loss: 0.8797 - val_accuracy: 0.7778\n",
      "Epoch 4/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.1569 - accuracy: 0.9462 - val_loss: 0.5851 - val_accuracy: 0.8163\n",
      "Epoch 5/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.1300 - accuracy: 0.9578 - val_loss: 0.3523 - val_accuracy: 0.8931\n",
      "Epoch 6/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0842 - accuracy: 0.9728 - val_loss: 0.2467 - val_accuracy: 0.9237\n",
      "Epoch 7/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0730 - accuracy: 0.9731 - val_loss: 0.6115 - val_accuracy: 0.8247\n",
      "Epoch 8/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0883 - accuracy: 0.9698 - val_loss: 0.9642 - val_accuracy: 0.7750\n",
      "Epoch 9/60\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.0548 - accuracy: 0.9832 - val_loss: 0.4678 - val_accuracy: 0.8791\n",
      "Epoch 10/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0479 - accuracy: 0.9842 - val_loss: 0.3562 - val_accuracy: 0.9019\n",
      "Epoch 11/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0417 - accuracy: 0.9871 - val_loss: 0.2505 - val_accuracy: 0.9297\n",
      "Epoch 12/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0434 - accuracy: 0.9848 - val_loss: 0.4084 - val_accuracy: 0.8925\n",
      "Epoch 13/60\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 0.0532 - accuracy: 0.9840 - val_loss: 0.2124 - val_accuracy: 0.9388\n",
      "Epoch 14/60\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 0.0250 - accuracy: 0.9913 - val_loss: 0.2778 - val_accuracy: 0.9331\n",
      "Epoch 15/60\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 0.0263 - accuracy: 0.9918 - val_loss: 0.4597 - val_accuracy: 0.8941\n",
      "Epoch 16/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0517 - accuracy: 0.9825 - val_loss: 0.1693 - val_accuracy: 0.9516\n",
      "Epoch 17/60\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 0.0288 - accuracy: 0.9912 - val_loss: 0.5300 - val_accuracy: 0.8750\n",
      "Epoch 18/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0276 - accuracy: 0.9908 - val_loss: 0.4323 - val_accuracy: 0.8966\n",
      "Epoch 19/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0228 - accuracy: 0.9913 - val_loss: 0.4278 - val_accuracy: 0.9084\n",
      "Epoch 20/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0260 - accuracy: 0.9914 - val_loss: 0.1624 - val_accuracy: 0.9600\n",
      "Epoch 21/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0095 - accuracy: 0.9970 - val_loss: 0.5020 - val_accuracy: 0.9062\n",
      "Epoch 22/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0305 - accuracy: 0.9891 - val_loss: 0.2382 - val_accuracy: 0.9372\n",
      "Epoch 23/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0141 - accuracy: 0.9955 - val_loss: 0.2563 - val_accuracy: 0.9384\n",
      "Epoch 24/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0069 - accuracy: 0.9985 - val_loss: 0.3743 - val_accuracy: 0.9219\n",
      "Epoch 25/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0138 - accuracy: 0.9950 - val_loss: 0.3297 - val_accuracy: 0.9316\n",
      "Epoch 26/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0139 - accuracy: 0.9959 - val_loss: 0.3655 - val_accuracy: 0.9175\n",
      "Epoch 27/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0311 - accuracy: 0.9903 - val_loss: 0.3519 - val_accuracy: 0.9294\n",
      "Epoch 28/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0138 - accuracy: 0.9972 - val_loss: 0.2041 - val_accuracy: 0.9469\n",
      "Epoch 29/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0149 - accuracy: 0.9949 - val_loss: 0.1668 - val_accuracy: 0.9544\n",
      "Epoch 30/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0073 - accuracy: 0.9978 - val_loss: 0.1861 - val_accuracy: 0.9572\n",
      "Epoch 31/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0139 - accuracy: 0.9952 - val_loss: 0.2889 - val_accuracy: 0.9403\n",
      "Epoch 32/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0120 - accuracy: 0.9956 - val_loss: 0.1912 - val_accuracy: 0.9575\n",
      "Epoch 33/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0034 - accuracy: 0.9993 - val_loss: 1.0194 - val_accuracy: 0.8497\n",
      "Epoch 34/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0263 - accuracy: 0.9915 - val_loss: 0.2793 - val_accuracy: 0.9409\n",
      "Epoch 35/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0434 - accuracy: 0.9872 - val_loss: 0.2050 - val_accuracy: 0.9472\n",
      "Epoch 36/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0076 - accuracy: 0.9972 - val_loss: 0.2168 - val_accuracy: 0.9447\n",
      "Epoch 37/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0055 - accuracy: 0.9985 - val_loss: 0.1970 - val_accuracy: 0.9516\n",
      "Epoch 38/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0126 - accuracy: 0.9955 - val_loss: 0.2657 - val_accuracy: 0.9503\n",
      "Epoch 39/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0085 - accuracy: 0.9966 - val_loss: 0.2759 - val_accuracy: 0.9478\n",
      "Epoch 40/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0091 - accuracy: 0.9971 - val_loss: 0.2289 - val_accuracy: 0.9472\n",
      "Epoch 00040: early stopping\n",
      "Melhor Accuracy de Treino:  0.9959999918937683\n",
      "Melhor Accuracy de Validação:  0.9599999785423279\n",
      "Treinando o modelo...\n",
      "Epoch 1/60\n",
      "375/375 [==============================] - 4s 9ms/step - loss: 0.7688 - accuracy: 0.7483 - val_loss: 3.7997 - val_accuracy: 0.3644\n",
      "Epoch 2/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.2760 - accuracy: 0.9072 - val_loss: 0.3771 - val_accuracy: 0.8712\n",
      "Epoch 3/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.1929 - accuracy: 0.9376 - val_loss: 0.4295 - val_accuracy: 0.8709\n",
      "Epoch 4/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.1330 - accuracy: 0.9566 - val_loss: 0.2072 - val_accuracy: 0.9275\n",
      "Epoch 5/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.1245 - accuracy: 0.9582 - val_loss: 0.4635 - val_accuracy: 0.8809\n",
      "Epoch 6/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0767 - accuracy: 0.9734 - val_loss: 0.2268 - val_accuracy: 0.9322\n",
      "Epoch 7/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0809 - accuracy: 0.9716 - val_loss: 0.2091 - val_accuracy: 0.9328\n",
      "Epoch 8/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0667 - accuracy: 0.9775 - val_loss: 0.3335 - val_accuracy: 0.8963\n",
      "Epoch 9/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0557 - accuracy: 0.9821 - val_loss: 0.3422 - val_accuracy: 0.9119\n",
      "Epoch 10/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0425 - accuracy: 0.9854 - val_loss: 0.4023 - val_accuracy: 0.8963\n",
      "Epoch 11/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0448 - accuracy: 0.9858 - val_loss: 0.2922 - val_accuracy: 0.9153\n",
      "Epoch 12/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0404 - accuracy: 0.9861 - val_loss: 0.3932 - val_accuracy: 0.8947\n",
      "Epoch 13/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0522 - accuracy: 0.9829 - val_loss: 0.2257 - val_accuracy: 0.9397\n",
      "Epoch 14/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0283 - accuracy: 0.9906 - val_loss: 0.2507 - val_accuracy: 0.9353\n",
      "Epoch 15/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0289 - accuracy: 0.9903 - val_loss: 0.1884 - val_accuracy: 0.9509\n",
      "Epoch 16/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0308 - accuracy: 0.9902 - val_loss: 0.3071 - val_accuracy: 0.9178\n",
      "Epoch 17/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0326 - accuracy: 0.9910 - val_loss: 0.2601 - val_accuracy: 0.9325\n",
      "Epoch 18/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0237 - accuracy: 0.9914 - val_loss: 0.2080 - val_accuracy: 0.9438\n",
      "Epoch 19/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0178 - accuracy: 0.9947 - val_loss: 0.2426 - val_accuracy: 0.9322\n",
      "Epoch 20/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0238 - accuracy: 0.9906 - val_loss: 0.3997 - val_accuracy: 0.9137\n",
      "Epoch 21/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0251 - accuracy: 0.9915 - val_loss: 0.4365 - val_accuracy: 0.9103\n",
      "Epoch 22/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0306 - accuracy: 0.9897 - val_loss: 0.4282 - val_accuracy: 0.9047\n",
      "Epoch 23/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0151 - accuracy: 0.9959 - val_loss: 0.2623 - val_accuracy: 0.9328\n",
      "Epoch 24/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0152 - accuracy: 0.9955 - val_loss: 0.2772 - val_accuracy: 0.9325\n",
      "Epoch 25/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0170 - accuracy: 0.9949 - val_loss: 0.4491 - val_accuracy: 0.8934\n",
      "Epoch 26/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0181 - accuracy: 0.9938 - val_loss: 0.1788 - val_accuracy: 0.9481\n",
      "Epoch 27/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0176 - accuracy: 0.9946 - val_loss: 0.2267 - val_accuracy: 0.9466\n",
      "Epoch 28/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0169 - accuracy: 0.9944 - val_loss: 0.1801 - val_accuracy: 0.9516\n",
      "Epoch 29/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0159 - accuracy: 0.9945 - val_loss: 0.1969 - val_accuracy: 0.9472\n",
      "Epoch 30/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0120 - accuracy: 0.9961 - val_loss: 0.1930 - val_accuracy: 0.9522\n",
      "Epoch 31/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0084 - accuracy: 0.9971 - val_loss: 0.1904 - val_accuracy: 0.9544\n",
      "Epoch 32/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0106 - accuracy: 0.9967 - val_loss: 0.4015 - val_accuracy: 0.9166\n",
      "Epoch 33/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0208 - accuracy: 0.9938 - val_loss: 0.2050 - val_accuracy: 0.9438\n",
      "Epoch 34/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0217 - accuracy: 0.9934 - val_loss: 0.1732 - val_accuracy: 0.9547\n",
      "Epoch 35/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0035 - accuracy: 0.9991 - val_loss: 0.2878 - val_accuracy: 0.9369\n",
      "Epoch 36/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0061 - accuracy: 0.9986 - val_loss: 0.3290 - val_accuracy: 0.9284\n",
      "Epoch 37/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0150 - accuracy: 0.9945 - val_loss: 0.2396 - val_accuracy: 0.9425\n",
      "Epoch 38/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0162 - accuracy: 0.9954 - val_loss: 0.1962 - val_accuracy: 0.9550\n",
      "Epoch 39/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0038 - accuracy: 0.9989 - val_loss: 0.2849 - val_accuracy: 0.9362\n",
      "Epoch 40/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0123 - accuracy: 0.9956 - val_loss: 0.2850 - val_accuracy: 0.9375\n",
      "Epoch 41/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0184 - accuracy: 0.9934 - val_loss: 0.1853 - val_accuracy: 0.9547\n",
      "Epoch 42/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0064 - accuracy: 0.9977 - val_loss: 0.1771 - val_accuracy: 0.9519\n",
      "Epoch 43/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0060 - accuracy: 0.9979 - val_loss: 0.2119 - val_accuracy: 0.9503\n",
      "Epoch 44/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0096 - accuracy: 0.9970 - val_loss: 0.3333 - val_accuracy: 0.9178\n",
      "Epoch 45/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0127 - accuracy: 0.9967 - val_loss: 0.3316 - val_accuracy: 0.9322\n",
      "Epoch 46/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0083 - accuracy: 0.9972 - val_loss: 0.2333 - val_accuracy: 0.9447\n",
      "Epoch 47/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0147 - accuracy: 0.9953 - val_loss: 0.2840 - val_accuracy: 0.9369\n",
      "Epoch 48/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0058 - accuracy: 0.9981 - val_loss: 0.2025 - val_accuracy: 0.9550\n",
      "Epoch 49/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0127 - accuracy: 0.9950 - val_loss: 0.2088 - val_accuracy: 0.9519\n",
      "Epoch 50/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0038 - accuracy: 0.9984 - val_loss: 0.3394 - val_accuracy: 0.9372\n",
      "Epoch 51/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0061 - accuracy: 0.9978 - val_loss: 0.1839 - val_accuracy: 0.9581\n",
      "Epoch 52/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0045 - accuracy: 0.9985 - val_loss: 0.4532 - val_accuracy: 0.9194\n",
      "Epoch 53/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0149 - accuracy: 0.9955 - val_loss: 0.4186 - val_accuracy: 0.9184\n",
      "Epoch 54/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0201 - accuracy: 0.9950 - val_loss: 0.2146 - val_accuracy: 0.9500\n",
      "Epoch 00054: early stopping\n",
      "Melhor Accuracy de Treino:  0.9960833191871643\n",
      "Melhor Accuracy de Validação:  0.9581249952316284\n",
      "Treinando o modelo...\n",
      "Epoch 1/60\n",
      "375/375 [==============================] - 4s 9ms/step - loss: 0.7849 - accuracy: 0.7445 - val_loss: 1.2809 - val_accuracy: 0.5934\n",
      "Epoch 2/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.2858 - accuracy: 0.9099 - val_loss: 0.2828 - val_accuracy: 0.8972\n",
      "Epoch 3/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.1890 - accuracy: 0.9387 - val_loss: 0.3541 - val_accuracy: 0.8847\n",
      "Epoch 4/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.1409 - accuracy: 0.9552 - val_loss: 0.6832 - val_accuracy: 0.7828\n",
      "Epoch 5/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.1119 - accuracy: 0.9612 - val_loss: 0.2514 - val_accuracy: 0.9131\n",
      "Epoch 6/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.1049 - accuracy: 0.9648 - val_loss: 0.2159 - val_accuracy: 0.9281\n",
      "Epoch 7/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0704 - accuracy: 0.9765 - val_loss: 0.3755 - val_accuracy: 0.8853\n",
      "Epoch 8/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0607 - accuracy: 0.9795 - val_loss: 0.5772 - val_accuracy: 0.8506\n",
      "Epoch 9/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0648 - accuracy: 0.9772 - val_loss: 0.2453 - val_accuracy: 0.9291\n",
      "Epoch 10/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0443 - accuracy: 0.9858 - val_loss: 0.2508 - val_accuracy: 0.9262\n",
      "Epoch 11/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0484 - accuracy: 0.9842 - val_loss: 0.5782 - val_accuracy: 0.8512\n",
      "Epoch 12/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0443 - accuracy: 0.9859 - val_loss: 0.6130 - val_accuracy: 0.8687\n",
      "Epoch 13/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0366 - accuracy: 0.9864 - val_loss: 0.2905 - val_accuracy: 0.9225\n",
      "Epoch 14/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0321 - accuracy: 0.9916 - val_loss: 0.2423 - val_accuracy: 0.9344\n",
      "Epoch 15/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0308 - accuracy: 0.9888 - val_loss: 0.1991 - val_accuracy: 0.9413\n",
      "Epoch 16/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0346 - accuracy: 0.9879 - val_loss: 0.1895 - val_accuracy: 0.9431\n",
      "Epoch 17/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0200 - accuracy: 0.9937 - val_loss: 0.2585 - val_accuracy: 0.9356\n",
      "Epoch 18/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0208 - accuracy: 0.9945 - val_loss: 0.4428 - val_accuracy: 0.9000\n",
      "Epoch 19/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0232 - accuracy: 0.9940 - val_loss: 0.1779 - val_accuracy: 0.9481\n",
      "Epoch 20/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0293 - accuracy: 0.9896 - val_loss: 0.3669 - val_accuracy: 0.9172\n",
      "Epoch 21/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0252 - accuracy: 0.9922 - val_loss: 0.1948 - val_accuracy: 0.9484\n",
      "Epoch 22/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0155 - accuracy: 0.9952 - val_loss: 0.3393 - val_accuracy: 0.9100\n",
      "Epoch 23/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0330 - accuracy: 0.9879 - val_loss: 0.4311 - val_accuracy: 0.9162\n",
      "Epoch 24/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0104 - accuracy: 0.9970 - val_loss: 0.1850 - val_accuracy: 0.9481\n",
      "Epoch 25/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0087 - accuracy: 0.9973 - val_loss: 0.2103 - val_accuracy: 0.9509\n",
      "Epoch 26/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0180 - accuracy: 0.9925 - val_loss: 0.1938 - val_accuracy: 0.9481\n",
      "Epoch 27/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0211 - accuracy: 0.9930 - val_loss: 0.3113 - val_accuracy: 0.9372\n",
      "Epoch 28/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0219 - accuracy: 0.9920 - val_loss: 0.3828 - val_accuracy: 0.9131\n",
      "Epoch 29/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0172 - accuracy: 0.9944 - val_loss: 0.1704 - val_accuracy: 0.9522\n",
      "Epoch 30/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0087 - accuracy: 0.9970 - val_loss: 0.1823 - val_accuracy: 0.9544\n",
      "Epoch 31/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0154 - accuracy: 0.9948 - val_loss: 0.2056 - val_accuracy: 0.9509\n",
      "Epoch 32/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0160 - accuracy: 0.9948 - val_loss: 0.4048 - val_accuracy: 0.9125\n",
      "Epoch 33/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0164 - accuracy: 0.9949 - val_loss: 0.4408 - val_accuracy: 0.9078\n",
      "Epoch 34/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0147 - accuracy: 0.9958 - val_loss: 0.1536 - val_accuracy: 0.9631\n",
      "Epoch 35/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0065 - accuracy: 0.9977 - val_loss: 0.2060 - val_accuracy: 0.9472\n",
      "Epoch 36/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0261 - accuracy: 0.9926 - val_loss: 0.3162 - val_accuracy: 0.9222\n",
      "Epoch 37/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0044 - accuracy: 0.9985 - val_loss: 0.1330 - val_accuracy: 0.9638\n",
      "Epoch 38/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0083 - accuracy: 0.9981 - val_loss: 0.2101 - val_accuracy: 0.9447\n",
      "Epoch 39/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0064 - accuracy: 0.9984 - val_loss: 0.3302 - val_accuracy: 0.9278\n",
      "Epoch 40/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0134 - accuracy: 0.9952 - val_loss: 0.2059 - val_accuracy: 0.9497\n",
      "Epoch 41/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0125 - accuracy: 0.9955 - val_loss: 0.4101 - val_accuracy: 0.9178\n",
      "Epoch 42/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0097 - accuracy: 0.9979 - val_loss: 0.2872 - val_accuracy: 0.9356\n",
      "Epoch 43/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0141 - accuracy: 0.9942 - val_loss: 0.2170 - val_accuracy: 0.9528\n",
      "Epoch 44/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0069 - accuracy: 0.9980 - val_loss: 0.1951 - val_accuracy: 0.9544\n",
      "Epoch 45/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0074 - accuracy: 0.9981 - val_loss: 0.1847 - val_accuracy: 0.9541\n",
      "Epoch 46/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0030 - accuracy: 0.9990 - val_loss: 0.2079 - val_accuracy: 0.9541\n",
      "Epoch 47/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0083 - accuracy: 0.9975 - val_loss: 0.3709 - val_accuracy: 0.9206\n",
      "Epoch 48/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0154 - accuracy: 0.9942 - val_loss: 0.2615 - val_accuracy: 0.9419\n",
      "Epoch 49/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0082 - accuracy: 0.9973 - val_loss: 0.2084 - val_accuracy: 0.9513\n",
      "Epoch 50/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0092 - accuracy: 0.9976 - val_loss: 0.3253 - val_accuracy: 0.9328\n",
      "Epoch 51/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0161 - accuracy: 0.9950 - val_loss: 0.3029 - val_accuracy: 0.9347\n",
      "Epoch 52/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0065 - accuracy: 0.9979 - val_loss: 0.2826 - val_accuracy: 0.9381\n",
      "Epoch 53/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0086 - accuracy: 0.9975 - val_loss: 0.1666 - val_accuracy: 0.9613\n",
      "Epoch 54/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0117 - accuracy: 0.9960 - val_loss: 0.2639 - val_accuracy: 0.9456\n",
      "Epoch 55/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0116 - accuracy: 0.9964 - val_loss: 0.1352 - val_accuracy: 0.9650\n",
      "Epoch 56/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0029 - accuracy: 0.9990 - val_loss: 0.2666 - val_accuracy: 0.9444\n",
      "Epoch 57/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0053 - accuracy: 0.9985 - val_loss: 0.1828 - val_accuracy: 0.9572\n",
      "Epoch 00057: early stopping\n",
      "Melhor Accuracy de Treino:  0.9989166855812073\n",
      "Melhor Accuracy de Validação:  0.9649999737739563\n",
      "Treinando o modelo...\n",
      "Epoch 1/60\n",
      "375/375 [==============================] - 4s 9ms/step - loss: 0.7355 - accuracy: 0.7579 - val_loss: 1.1541 - val_accuracy: 0.6737\n",
      "Epoch 2/60\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.2697 - accuracy: 0.9112 - val_loss: 0.8637 - val_accuracy: 0.7584\n",
      "Epoch 3/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.2052 - accuracy: 0.9312 - val_loss: 1.3496 - val_accuracy: 0.6541\n",
      "Epoch 4/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.1479 - accuracy: 0.9494 - val_loss: 0.3883 - val_accuracy: 0.8859\n",
      "Epoch 5/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.1229 - accuracy: 0.9591 - val_loss: 0.3517 - val_accuracy: 0.8819\n",
      "Epoch 6/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0780 - accuracy: 0.9740 - val_loss: 0.3133 - val_accuracy: 0.9094\n",
      "Epoch 7/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0742 - accuracy: 0.9763 - val_loss: 0.2240 - val_accuracy: 0.9294\n",
      "Epoch 8/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0726 - accuracy: 0.9757 - val_loss: 0.2980 - val_accuracy: 0.9112\n",
      "Epoch 9/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0563 - accuracy: 0.9826 - val_loss: 0.3340 - val_accuracy: 0.9053\n",
      "Epoch 10/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0493 - accuracy: 0.9839 - val_loss: 0.8417 - val_accuracy: 0.8103\n",
      "Epoch 11/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0321 - accuracy: 0.9914 - val_loss: 0.6596 - val_accuracy: 0.8619\n",
      "Epoch 12/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0442 - accuracy: 0.9855 - val_loss: 0.2943 - val_accuracy: 0.9169\n",
      "Epoch 13/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0428 - accuracy: 0.9861 - val_loss: 0.4237 - val_accuracy: 0.9013\n",
      "Epoch 14/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0286 - accuracy: 0.9903 - val_loss: 0.2502 - val_accuracy: 0.9319\n",
      "Epoch 15/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0303 - accuracy: 0.9921 - val_loss: 0.2340 - val_accuracy: 0.9312\n",
      "Epoch 16/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0369 - accuracy: 0.9868 - val_loss: 0.5477 - val_accuracy: 0.8675\n",
      "Epoch 17/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0234 - accuracy: 0.9927 - val_loss: 0.2289 - val_accuracy: 0.9397\n",
      "Epoch 18/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0247 - accuracy: 0.9925 - val_loss: 0.1914 - val_accuracy: 0.9491\n",
      "Epoch 19/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0258 - accuracy: 0.9911 - val_loss: 0.3629 - val_accuracy: 0.9184\n",
      "Epoch 20/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0321 - accuracy: 0.9890 - val_loss: 0.2054 - val_accuracy: 0.9431\n",
      "Epoch 21/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0140 - accuracy: 0.9951 - val_loss: 0.3651 - val_accuracy: 0.9150\n",
      "Epoch 22/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0261 - accuracy: 0.9915 - val_loss: 0.3187 - val_accuracy: 0.9281\n",
      "Epoch 23/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0133 - accuracy: 0.9969 - val_loss: 0.1523 - val_accuracy: 0.9616\n",
      "Epoch 24/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0164 - accuracy: 0.9946 - val_loss: 0.1956 - val_accuracy: 0.9459\n",
      "Epoch 25/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0161 - accuracy: 0.9942 - val_loss: 0.2080 - val_accuracy: 0.9450\n",
      "Epoch 26/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0221 - accuracy: 0.9927 - val_loss: 0.2217 - val_accuracy: 0.9444\n",
      "Epoch 27/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0079 - accuracy: 0.9978 - val_loss: 0.2144 - val_accuracy: 0.9450\n",
      "Epoch 28/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0186 - accuracy: 0.9939 - val_loss: 0.2502 - val_accuracy: 0.9431\n",
      "Epoch 29/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0147 - accuracy: 0.9956 - val_loss: 0.1741 - val_accuracy: 0.9569\n",
      "Epoch 30/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0210 - accuracy: 0.9947 - val_loss: 0.2782 - val_accuracy: 0.9275\n",
      "Epoch 31/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0153 - accuracy: 0.9948 - val_loss: 0.2631 - val_accuracy: 0.9369\n",
      "Epoch 32/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0169 - accuracy: 0.9936 - val_loss: 0.2581 - val_accuracy: 0.9388\n",
      "Epoch 33/60\n",
      "375/375 [==============================] - 4s 9ms/step - loss: 0.0103 - accuracy: 0.9971 - val_loss: 0.2198 - val_accuracy: 0.9481\n",
      "Epoch 34/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0146 - accuracy: 0.9948 - val_loss: 0.2210 - val_accuracy: 0.9506\n",
      "Epoch 35/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0080 - accuracy: 0.9975 - val_loss: 0.1953 - val_accuracy: 0.9509\n",
      "Epoch 36/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0106 - accuracy: 0.9973 - val_loss: 0.2714 - val_accuracy: 0.9369\n",
      "Epoch 37/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0249 - accuracy: 0.9920 - val_loss: 0.2664 - val_accuracy: 0.9416\n",
      "Epoch 38/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0143 - accuracy: 0.9956 - val_loss: 0.2513 - val_accuracy: 0.9413\n",
      "Epoch 39/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0114 - accuracy: 0.9962 - val_loss: 0.1825 - val_accuracy: 0.9572\n",
      "Epoch 40/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0078 - accuracy: 0.9972 - val_loss: 0.2339 - val_accuracy: 0.9456\n",
      "Epoch 41/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0102 - accuracy: 0.9968 - val_loss: 0.1757 - val_accuracy: 0.9575\n",
      "Epoch 42/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0102 - accuracy: 0.9964 - val_loss: 0.4985 - val_accuracy: 0.9050\n",
      "Epoch 43/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0138 - accuracy: 0.9948 - val_loss: 0.2373 - val_accuracy: 0.9550\n",
      "Epoch 00043: early stopping\n",
      "Melhor Accuracy de Treino:  0.9959999918937683\n",
      "Melhor Accuracy de Validação:  0.9615625143051147\n",
      "Treinando o modelo...\n",
      "Epoch 1/60\n",
      "375/375 [==============================] - 4s 9ms/step - loss: 0.8176 - accuracy: 0.7452 - val_loss: 0.7699 - val_accuracy: 0.7600\n",
      "Epoch 2/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.2713 - accuracy: 0.9149 - val_loss: 0.3674 - val_accuracy: 0.8791\n",
      "Epoch 3/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.1867 - accuracy: 0.9393 - val_loss: 0.3775 - val_accuracy: 0.8675\n",
      "Epoch 4/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.1442 - accuracy: 0.9509 - val_loss: 0.2406 - val_accuracy: 0.9259\n",
      "Epoch 5/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.1157 - accuracy: 0.9600 - val_loss: 0.5361 - val_accuracy: 0.8587\n",
      "Epoch 6/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0861 - accuracy: 0.9705 - val_loss: 0.4548 - val_accuracy: 0.8778\n",
      "Epoch 7/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0851 - accuracy: 0.9720 - val_loss: 0.2689 - val_accuracy: 0.9191\n",
      "Epoch 8/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0702 - accuracy: 0.9762 - val_loss: 0.2402 - val_accuracy: 0.9237\n",
      "Epoch 9/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0474 - accuracy: 0.9837 - val_loss: 0.5918 - val_accuracy: 0.8522\n",
      "Epoch 10/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0592 - accuracy: 0.9783 - val_loss: 0.2366 - val_accuracy: 0.9294\n",
      "Epoch 11/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0410 - accuracy: 0.9853 - val_loss: 0.5391 - val_accuracy: 0.8741\n",
      "Epoch 12/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0491 - accuracy: 0.9827 - val_loss: 0.2446 - val_accuracy: 0.9403\n",
      "Epoch 13/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0364 - accuracy: 0.9872 - val_loss: 0.2125 - val_accuracy: 0.9406\n",
      "Epoch 14/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0214 - accuracy: 0.9933 - val_loss: 0.3148 - val_accuracy: 0.9319\n",
      "Epoch 15/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0314 - accuracy: 0.9896 - val_loss: 0.2439 - val_accuracy: 0.9306\n",
      "Epoch 16/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0339 - accuracy: 0.9889 - val_loss: 0.1692 - val_accuracy: 0.9534\n",
      "Epoch 17/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0301 - accuracy: 0.9911 - val_loss: 0.1976 - val_accuracy: 0.9409\n",
      "Epoch 18/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0164 - accuracy: 0.9945 - val_loss: 0.1661 - val_accuracy: 0.9563\n",
      "Epoch 19/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0144 - accuracy: 0.9959 - val_loss: 0.3497 - val_accuracy: 0.9162\n",
      "Epoch 20/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0186 - accuracy: 0.9943 - val_loss: 0.4589 - val_accuracy: 0.8975\n",
      "Epoch 21/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0236 - accuracy: 0.9927 - val_loss: 0.2651 - val_accuracy: 0.9344\n",
      "Epoch 22/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0162 - accuracy: 0.9943 - val_loss: 0.4224 - val_accuracy: 0.9119\n",
      "Epoch 23/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0276 - accuracy: 0.9906 - val_loss: 0.1937 - val_accuracy: 0.9509\n",
      "Epoch 24/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0097 - accuracy: 0.9972 - val_loss: 0.2182 - val_accuracy: 0.9488\n",
      "Epoch 25/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0225 - accuracy: 0.9927 - val_loss: 0.1906 - val_accuracy: 0.9541\n",
      "Epoch 26/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0131 - accuracy: 0.9953 - val_loss: 0.3057 - val_accuracy: 0.9309\n",
      "Epoch 27/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0189 - accuracy: 0.9943 - val_loss: 0.2257 - val_accuracy: 0.9400\n",
      "Epoch 28/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0117 - accuracy: 0.9961 - val_loss: 0.4239 - val_accuracy: 0.9244\n",
      "Epoch 29/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0248 - accuracy: 0.9932 - val_loss: 0.1827 - val_accuracy: 0.9509\n",
      "Epoch 30/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0146 - accuracy: 0.9960 - val_loss: 0.1868 - val_accuracy: 0.9544\n",
      "Epoch 31/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0137 - accuracy: 0.9960 - val_loss: 0.2365 - val_accuracy: 0.9366\n",
      "Epoch 32/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0174 - accuracy: 0.9943 - val_loss: 0.1676 - val_accuracy: 0.9553\n",
      "Epoch 33/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0099 - accuracy: 0.9967 - val_loss: 0.2627 - val_accuracy: 0.9409\n",
      "Epoch 34/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0070 - accuracy: 0.9978 - val_loss: 0.2227 - val_accuracy: 0.9441\n",
      "Epoch 35/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0211 - accuracy: 0.9923 - val_loss: 0.3948 - val_accuracy: 0.9197\n",
      "Epoch 36/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0250 - accuracy: 0.9911 - val_loss: 0.3488 - val_accuracy: 0.9322\n",
      "Epoch 37/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0063 - accuracy: 0.9985 - val_loss: 0.1777 - val_accuracy: 0.9550\n",
      "Epoch 38/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0034 - accuracy: 0.9988 - val_loss: 0.5624 - val_accuracy: 0.8950\n",
      "Epoch 00038: early stopping\n",
      "Melhor Accuracy de Treino:  0.9984999895095825\n",
      "Melhor Accuracy de Validação:  0.956250011920929\n",
      "Treinando o modelo...\n",
      "Epoch 1/60\n",
      "375/375 [==============================] - 4s 9ms/step - loss: 0.7924 - accuracy: 0.7397 - val_loss: 1.1764 - val_accuracy: 0.6888\n",
      "Epoch 2/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.2778 - accuracy: 0.9142 - val_loss: 0.7349 - val_accuracy: 0.7981\n",
      "Epoch 3/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.1998 - accuracy: 0.9318 - val_loss: 0.3663 - val_accuracy: 0.8744\n",
      "Epoch 4/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.1512 - accuracy: 0.9514 - val_loss: 0.6163 - val_accuracy: 0.8122\n",
      "Epoch 5/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.1223 - accuracy: 0.9572 - val_loss: 0.4639 - val_accuracy: 0.8656\n",
      "Epoch 6/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0965 - accuracy: 0.9688 - val_loss: 0.6050 - val_accuracy: 0.8394\n",
      "Epoch 7/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0747 - accuracy: 0.9752 - val_loss: 0.2677 - val_accuracy: 0.9184\n",
      "Epoch 8/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0571 - accuracy: 0.9820 - val_loss: 0.3788 - val_accuracy: 0.8894\n",
      "Epoch 9/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0679 - accuracy: 0.9752 - val_loss: 0.2681 - val_accuracy: 0.9191\n",
      "Epoch 10/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0496 - accuracy: 0.9820 - val_loss: 0.2314 - val_accuracy: 0.9306\n",
      "Epoch 11/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0435 - accuracy: 0.9849 - val_loss: 0.2304 - val_accuracy: 0.9347\n",
      "Epoch 12/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0476 - accuracy: 0.9838 - val_loss: 0.1790 - val_accuracy: 0.9491\n",
      "Epoch 13/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0293 - accuracy: 0.9900 - val_loss: 0.1877 - val_accuracy: 0.9469\n",
      "Epoch 14/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0374 - accuracy: 0.9866 - val_loss: 0.1792 - val_accuracy: 0.9513\n",
      "Epoch 15/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0241 - accuracy: 0.9923 - val_loss: 0.2724 - val_accuracy: 0.9319\n",
      "Epoch 16/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0190 - accuracy: 0.9935 - val_loss: 0.1914 - val_accuracy: 0.9497\n",
      "Epoch 17/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0224 - accuracy: 0.9928 - val_loss: 0.2481 - val_accuracy: 0.9372\n",
      "Epoch 18/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0508 - accuracy: 0.9844 - val_loss: 0.2385 - val_accuracy: 0.9347\n",
      "Epoch 19/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0196 - accuracy: 0.9948 - val_loss: 0.2168 - val_accuracy: 0.9441\n",
      "Epoch 20/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0193 - accuracy: 0.9946 - val_loss: 0.3225 - val_accuracy: 0.9228\n",
      "Epoch 21/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0197 - accuracy: 0.9937 - val_loss: 0.3840 - val_accuracy: 0.9084\n",
      "Epoch 22/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0247 - accuracy: 0.9920 - val_loss: 0.1500 - val_accuracy: 0.9544\n",
      "Epoch 23/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0119 - accuracy: 0.9956 - val_loss: 1.2247 - val_accuracy: 0.7781\n",
      "Epoch 24/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0307 - accuracy: 0.9889 - val_loss: 0.1844 - val_accuracy: 0.9519\n",
      "Epoch 25/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0120 - accuracy: 0.9972 - val_loss: 0.3472 - val_accuracy: 0.9169\n",
      "Epoch 26/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0113 - accuracy: 0.9968 - val_loss: 0.2118 - val_accuracy: 0.9488\n",
      "Epoch 27/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0088 - accuracy: 0.9974 - val_loss: 0.2664 - val_accuracy: 0.9294\n",
      "Epoch 28/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0262 - accuracy: 0.9910 - val_loss: 0.1557 - val_accuracy: 0.9550\n",
      "Epoch 29/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0151 - accuracy: 0.9932 - val_loss: 0.3032 - val_accuracy: 0.9300\n",
      "Epoch 30/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0251 - accuracy: 0.9922 - val_loss: 0.2041 - val_accuracy: 0.9466\n",
      "Epoch 31/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0130 - accuracy: 0.9961 - val_loss: 0.2096 - val_accuracy: 0.9522\n",
      "Epoch 32/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0064 - accuracy: 0.9980 - val_loss: 0.3068 - val_accuracy: 0.9337\n",
      "Epoch 33/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0178 - accuracy: 0.9947 - val_loss: 0.2215 - val_accuracy: 0.9463\n",
      "Epoch 34/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0076 - accuracy: 0.9978 - val_loss: 0.1967 - val_accuracy: 0.9497\n",
      "Epoch 35/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0131 - accuracy: 0.9966 - val_loss: 0.1575 - val_accuracy: 0.9588\n",
      "Epoch 36/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0130 - accuracy: 0.9957 - val_loss: 0.2869 - val_accuracy: 0.9334\n",
      "Epoch 37/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0188 - accuracy: 0.9945 - val_loss: 0.2884 - val_accuracy: 0.9353\n",
      "Epoch 38/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0041 - accuracy: 0.9987 - val_loss: 0.2131 - val_accuracy: 0.9491\n",
      "Epoch 39/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0117 - accuracy: 0.9958 - val_loss: 0.2390 - val_accuracy: 0.9488\n",
      "Epoch 40/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0176 - accuracy: 0.9939 - val_loss: 0.1762 - val_accuracy: 0.9600\n",
      "Epoch 41/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0062 - accuracy: 0.9981 - val_loss: 0.1644 - val_accuracy: 0.9578\n",
      "Epoch 42/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0056 - accuracy: 0.9982 - val_loss: 0.2234 - val_accuracy: 0.9500\n",
      "Epoch 00042: early stopping\n",
      "Melhor Accuracy de Treino:  0.9975000023841858\n",
      "Melhor Accuracy de Validação:  0.9599999785423279\n",
      "Treinando o modelo...\n",
      "Epoch 1/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.7510 - accuracy: 0.7589 - val_loss: 1.8405 - val_accuracy: 0.5534\n",
      "Epoch 2/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.2926 - accuracy: 0.9100 - val_loss: 1.1813 - val_accuracy: 0.7113\n",
      "Epoch 3/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.1921 - accuracy: 0.9384 - val_loss: 0.3780 - val_accuracy: 0.8772\n",
      "Epoch 4/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.1593 - accuracy: 0.9462 - val_loss: 0.5431 - val_accuracy: 0.8469\n",
      "Epoch 5/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.1279 - accuracy: 0.9577 - val_loss: 0.4044 - val_accuracy: 0.8766\n",
      "Epoch 6/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0941 - accuracy: 0.9684 - val_loss: 0.4129 - val_accuracy: 0.8744\n",
      "Epoch 7/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0740 - accuracy: 0.9747 - val_loss: 0.2396 - val_accuracy: 0.9262\n",
      "Epoch 8/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0512 - accuracy: 0.9835 - val_loss: 0.2296 - val_accuracy: 0.9306\n",
      "Epoch 9/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0637 - accuracy: 0.9759 - val_loss: 0.4261 - val_accuracy: 0.8809\n",
      "Epoch 10/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0788 - accuracy: 0.9734 - val_loss: 0.4248 - val_accuracy: 0.8856\n",
      "Epoch 11/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0487 - accuracy: 0.9804 - val_loss: 1.9060 - val_accuracy: 0.7122\n",
      "Epoch 12/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0560 - accuracy: 0.9824 - val_loss: 0.1846 - val_accuracy: 0.9444\n",
      "Epoch 13/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0275 - accuracy: 0.9914 - val_loss: 0.2964 - val_accuracy: 0.9244\n",
      "Epoch 14/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0356 - accuracy: 0.9880 - val_loss: 0.3280 - val_accuracy: 0.9181\n",
      "Epoch 15/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0377 - accuracy: 0.9865 - val_loss: 0.1732 - val_accuracy: 0.9469\n",
      "Epoch 16/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0157 - accuracy: 0.9947 - val_loss: 0.3895 - val_accuracy: 0.9041\n",
      "Epoch 17/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0296 - accuracy: 0.9890 - val_loss: 0.2253 - val_accuracy: 0.9353\n",
      "Epoch 18/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0180 - accuracy: 0.9942 - val_loss: 0.1570 - val_accuracy: 0.9522\n",
      "Epoch 19/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0200 - accuracy: 0.9933 - val_loss: 0.4583 - val_accuracy: 0.9028\n",
      "Epoch 20/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0340 - accuracy: 0.9882 - val_loss: 0.2261 - val_accuracy: 0.9438\n",
      "Epoch 21/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0167 - accuracy: 0.9954 - val_loss: 0.3740 - val_accuracy: 0.9212\n",
      "Epoch 22/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0182 - accuracy: 0.9953 - val_loss: 0.1937 - val_accuracy: 0.9481\n",
      "Epoch 23/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0148 - accuracy: 0.9952 - val_loss: 0.2312 - val_accuracy: 0.9400\n",
      "Epoch 24/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0236 - accuracy: 0.9921 - val_loss: 0.2113 - val_accuracy: 0.9453\n",
      "Epoch 25/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0146 - accuracy: 0.9950 - val_loss: 0.2212 - val_accuracy: 0.9403\n",
      "Epoch 26/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0197 - accuracy: 0.9940 - val_loss: 0.1871 - val_accuracy: 0.9500\n",
      "Epoch 27/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0107 - accuracy: 0.9967 - val_loss: 0.2783 - val_accuracy: 0.9369\n",
      "Epoch 28/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0145 - accuracy: 0.9945 - val_loss: 0.4706 - val_accuracy: 0.8988\n",
      "Epoch 29/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0292 - accuracy: 0.9907 - val_loss: 0.2093 - val_accuracy: 0.9478\n",
      "Epoch 30/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0092 - accuracy: 0.9974 - val_loss: 0.2006 - val_accuracy: 0.9488\n",
      "Epoch 31/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0119 - accuracy: 0.9960 - val_loss: 0.5349 - val_accuracy: 0.8859\n",
      "Epoch 32/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0198 - accuracy: 0.9939 - val_loss: 0.2410 - val_accuracy: 0.9469\n",
      "Epoch 33/60\n",
      "375/375 [==============================] - 4s 9ms/step - loss: 0.0149 - accuracy: 0.9941 - val_loss: 0.3118 - val_accuracy: 0.9319\n",
      "Epoch 34/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0147 - accuracy: 0.9949 - val_loss: 0.1875 - val_accuracy: 0.9500\n",
      "Epoch 35/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0090 - accuracy: 0.9968 - val_loss: 0.2394 - val_accuracy: 0.9406\n",
      "Epoch 36/60\n",
      "375/375 [==============================] - 4s 9ms/step - loss: 0.0058 - accuracy: 0.9983 - val_loss: 0.2206 - val_accuracy: 0.9497\n",
      "Epoch 37/60\n",
      "375/375 [==============================] - 4s 9ms/step - loss: 0.0052 - accuracy: 0.9977 - val_loss: 0.2658 - val_accuracy: 0.9409\n",
      "Epoch 38/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0274 - accuracy: 0.9910 - val_loss: 0.3624 - val_accuracy: 0.9125\n",
      "Epoch 00038: early stopping\n",
      "Melhor Accuracy de Treino:  0.9930833578109741\n",
      "Melhor Accuracy de Validação:  0.9521874785423279\n",
      "Treinando o modelo...\n",
      "Epoch 1/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.7744 - accuracy: 0.7557 - val_loss: 0.5809 - val_accuracy: 0.8106\n",
      "Epoch 2/60\n",
      "375/375 [==============================] - 4s 9ms/step - loss: 0.2799 - accuracy: 0.9096 - val_loss: 1.8929 - val_accuracy: 0.5550\n",
      "Epoch 3/60\n",
      "375/375 [==============================] - 4s 9ms/step - loss: 0.1991 - accuracy: 0.9328 - val_loss: 0.4458 - val_accuracy: 0.8600\n",
      "Epoch 4/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.1549 - accuracy: 0.9470 - val_loss: 0.5915 - val_accuracy: 0.8353\n",
      "Epoch 5/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.1177 - accuracy: 0.9582 - val_loss: 0.2662 - val_accuracy: 0.9112\n",
      "Epoch 6/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0954 - accuracy: 0.9674 - val_loss: 0.4332 - val_accuracy: 0.8828\n",
      "Epoch 7/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0808 - accuracy: 0.9757 - val_loss: 0.1789 - val_accuracy: 0.9409\n",
      "Epoch 8/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0584 - accuracy: 0.9804 - val_loss: 0.3113 - val_accuracy: 0.9078\n",
      "Epoch 9/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0554 - accuracy: 0.9821 - val_loss: 0.2849 - val_accuracy: 0.9259\n",
      "Epoch 10/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0473 - accuracy: 0.9827 - val_loss: 0.2425 - val_accuracy: 0.9241\n",
      "Epoch 11/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0411 - accuracy: 0.9851 - val_loss: 0.4008 - val_accuracy: 0.9019\n",
      "Epoch 12/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0433 - accuracy: 0.9845 - val_loss: 0.2217 - val_accuracy: 0.9362\n",
      "Epoch 13/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0408 - accuracy: 0.9873 - val_loss: 0.1800 - val_accuracy: 0.9481\n",
      "Epoch 14/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0280 - accuracy: 0.9910 - val_loss: 0.1990 - val_accuracy: 0.9397\n",
      "Epoch 15/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0183 - accuracy: 0.9945 - val_loss: 0.4203 - val_accuracy: 0.9028\n",
      "Epoch 16/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0285 - accuracy: 0.9903 - val_loss: 0.3102 - val_accuracy: 0.9231\n",
      "Epoch 17/60\n",
      "375/375 [==============================] - 4s 9ms/step - loss: 0.0213 - accuracy: 0.9934 - val_loss: 0.1934 - val_accuracy: 0.9456\n",
      "Epoch 18/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0375 - accuracy: 0.9881 - val_loss: 0.2516 - val_accuracy: 0.9378\n",
      "Epoch 19/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0207 - accuracy: 0.9922 - val_loss: 0.1980 - val_accuracy: 0.9484\n",
      "Epoch 20/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0281 - accuracy: 0.9901 - val_loss: 0.3458 - val_accuracy: 0.9222\n",
      "Epoch 21/60\n",
      "375/375 [==============================] - 4s 9ms/step - loss: 0.0170 - accuracy: 0.9946 - val_loss: 0.1515 - val_accuracy: 0.9603\n",
      "Epoch 22/60\n",
      "375/375 [==============================] - 4s 9ms/step - loss: 0.0139 - accuracy: 0.9962 - val_loss: 0.5049 - val_accuracy: 0.8903\n",
      "Epoch 23/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0287 - accuracy: 0.9897 - val_loss: 0.2342 - val_accuracy: 0.9397\n",
      "Epoch 24/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0176 - accuracy: 0.9938 - val_loss: 0.2574 - val_accuracy: 0.9384\n",
      "Epoch 25/60\n",
      "375/375 [==============================] - 4s 9ms/step - loss: 0.0143 - accuracy: 0.9957 - val_loss: 0.1807 - val_accuracy: 0.9513\n",
      "Epoch 26/60\n",
      "375/375 [==============================] - 4s 9ms/step - loss: 0.0140 - accuracy: 0.9955 - val_loss: 0.5065 - val_accuracy: 0.8953\n",
      "Epoch 27/60\n",
      "375/375 [==============================] - 4s 9ms/step - loss: 0.0214 - accuracy: 0.9932 - val_loss: 0.2481 - val_accuracy: 0.9359\n",
      "Epoch 28/60\n",
      "375/375 [==============================] - 4s 9ms/step - loss: 0.0156 - accuracy: 0.9952 - val_loss: 0.2217 - val_accuracy: 0.9459\n",
      "Epoch 29/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0101 - accuracy: 0.9965 - val_loss: 0.2910 - val_accuracy: 0.9262\n",
      "Epoch 30/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0296 - accuracy: 0.9902 - val_loss: 0.2131 - val_accuracy: 0.9419\n",
      "Epoch 31/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0110 - accuracy: 0.9959 - val_loss: 0.2074 - val_accuracy: 0.9497\n",
      "Epoch 32/60\n",
      "375/375 [==============================] - 4s 9ms/step - loss: 0.0178 - accuracy: 0.9948 - val_loss: 0.2587 - val_accuracy: 0.9444\n",
      "Epoch 33/60\n",
      "375/375 [==============================] - 4s 9ms/step - loss: 0.0146 - accuracy: 0.9947 - val_loss: 0.2447 - val_accuracy: 0.9469\n",
      "Epoch 34/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0090 - accuracy: 0.9974 - val_loss: 0.2514 - val_accuracy: 0.9441\n",
      "Epoch 35/60\n",
      "375/375 [==============================] - 4s 9ms/step - loss: 0.0093 - accuracy: 0.9966 - val_loss: 0.3649 - val_accuracy: 0.9341\n",
      "Epoch 36/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0114 - accuracy: 0.9962 - val_loss: 0.1933 - val_accuracy: 0.9534\n",
      "Epoch 37/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0115 - accuracy: 0.9965 - val_loss: 0.2005 - val_accuracy: 0.9500\n",
      "Epoch 38/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0164 - accuracy: 0.9945 - val_loss: 0.3803 - val_accuracy: 0.9256\n",
      "Epoch 39/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0108 - accuracy: 0.9965 - val_loss: 0.2501 - val_accuracy: 0.9450\n",
      "Epoch 40/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0081 - accuracy: 0.9973 - val_loss: 0.2137 - val_accuracy: 0.9528\n",
      "Epoch 41/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0071 - accuracy: 0.9979 - val_loss: 0.3681 - val_accuracy: 0.9278\n",
      "Epoch 00041: early stopping\n",
      "Melhor Accuracy de Treino:  0.9965000152587891\n",
      "Melhor Accuracy de Validação:  0.9603124856948853\n",
      "Treinando o modelo...\n",
      "Epoch 1/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.7470 - accuracy: 0.7497 - val_loss: 1.4573 - val_accuracy: 0.6019\n",
      "Epoch 2/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.2855 - accuracy: 0.9079 - val_loss: 0.5887 - val_accuracy: 0.8050\n",
      "Epoch 3/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.1917 - accuracy: 0.9369 - val_loss: 0.7905 - val_accuracy: 0.7703\n",
      "Epoch 4/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.1564 - accuracy: 0.9489 - val_loss: 0.7564 - val_accuracy: 0.7809\n",
      "Epoch 5/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.1148 - accuracy: 0.9619 - val_loss: 0.5327 - val_accuracy: 0.8388\n",
      "Epoch 6/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0979 - accuracy: 0.9673 - val_loss: 0.2432 - val_accuracy: 0.9203\n",
      "Epoch 7/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.1001 - accuracy: 0.9660 - val_loss: 0.4112 - val_accuracy: 0.8853\n",
      "Epoch 8/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0735 - accuracy: 0.9770 - val_loss: 0.2078 - val_accuracy: 0.9337\n",
      "Epoch 9/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0508 - accuracy: 0.9828 - val_loss: 0.4389 - val_accuracy: 0.8791\n",
      "Epoch 10/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0366 - accuracy: 0.9886 - val_loss: 0.2735 - val_accuracy: 0.9234\n",
      "Epoch 11/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0402 - accuracy: 0.9848 - val_loss: 0.4368 - val_accuracy: 0.8828\n",
      "Epoch 12/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0510 - accuracy: 0.9823 - val_loss: 0.3077 - val_accuracy: 0.9112\n",
      "Epoch 13/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0278 - accuracy: 0.9914 - val_loss: 0.4020 - val_accuracy: 0.8947\n",
      "Epoch 14/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0434 - accuracy: 0.9857 - val_loss: 0.3356 - val_accuracy: 0.9091\n",
      "Epoch 15/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0285 - accuracy: 0.9888 - val_loss: 0.1705 - val_accuracy: 0.9456\n",
      "Epoch 16/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0214 - accuracy: 0.9940 - val_loss: 0.3683 - val_accuracy: 0.9131\n",
      "Epoch 17/60\n",
      "375/375 [==============================] - 4s 9ms/step - loss: 0.0298 - accuracy: 0.9905 - val_loss: 0.2883 - val_accuracy: 0.9284\n",
      "Epoch 18/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0196 - accuracy: 0.9925 - val_loss: 0.2699 - val_accuracy: 0.9309\n",
      "Epoch 19/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0249 - accuracy: 0.9924 - val_loss: 0.3801 - val_accuracy: 0.9081\n",
      "Epoch 20/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0317 - accuracy: 0.9896 - val_loss: 0.3279 - val_accuracy: 0.9234\n",
      "Epoch 21/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0312 - accuracy: 0.9894 - val_loss: 0.1636 - val_accuracy: 0.9528\n",
      "Epoch 22/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0114 - accuracy: 0.9961 - val_loss: 0.1679 - val_accuracy: 0.9556\n",
      "Epoch 23/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0119 - accuracy: 0.9963 - val_loss: 0.1406 - val_accuracy: 0.9591\n",
      "Epoch 24/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0128 - accuracy: 0.9955 - val_loss: 0.4856 - val_accuracy: 0.9028\n",
      "Epoch 25/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0360 - accuracy: 0.9876 - val_loss: 0.1367 - val_accuracy: 0.9588\n",
      "Epoch 26/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0157 - accuracy: 0.9949 - val_loss: 0.1908 - val_accuracy: 0.9469\n",
      "Epoch 27/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0061 - accuracy: 0.9977 - val_loss: 0.3641 - val_accuracy: 0.9256\n",
      "Epoch 28/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0262 - accuracy: 0.9907 - val_loss: 0.3939 - val_accuracy: 0.9125\n",
      "Epoch 29/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0181 - accuracy: 0.9943 - val_loss: 0.1724 - val_accuracy: 0.9594\n",
      "Epoch 30/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0066 - accuracy: 0.9982 - val_loss: 0.1804 - val_accuracy: 0.9522\n",
      "Epoch 31/60\n",
      "375/375 [==============================] - 4s 9ms/step - loss: 0.0146 - accuracy: 0.9951 - val_loss: 0.2169 - val_accuracy: 0.9469\n",
      "Epoch 32/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0084 - accuracy: 0.9975 - val_loss: 0.1758 - val_accuracy: 0.9541\n",
      "Epoch 33/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0075 - accuracy: 0.9979 - val_loss: 0.7738 - val_accuracy: 0.8694\n",
      "Epoch 34/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0361 - accuracy: 0.9880 - val_loss: 0.2398 - val_accuracy: 0.9400\n",
      "Epoch 35/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0104 - accuracy: 0.9970 - val_loss: 0.2387 - val_accuracy: 0.9453\n",
      "Epoch 36/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0093 - accuracy: 0.9974 - val_loss: 0.2063 - val_accuracy: 0.9466\n",
      "Epoch 37/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0081 - accuracy: 0.9972 - val_loss: 0.2153 - val_accuracy: 0.9481\n",
      "Epoch 38/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0044 - accuracy: 0.9990 - val_loss: 0.2711 - val_accuracy: 0.9400\n",
      "Epoch 39/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0124 - accuracy: 0.9961 - val_loss: 0.2106 - val_accuracy: 0.9519\n",
      "Epoch 40/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0102 - accuracy: 0.9965 - val_loss: 0.2100 - val_accuracy: 0.9534\n",
      "Epoch 41/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0210 - accuracy: 0.9941 - val_loss: 0.1897 - val_accuracy: 0.9544\n",
      "Epoch 42/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0051 - accuracy: 0.9985 - val_loss: 0.2043 - val_accuracy: 0.9469\n",
      "Epoch 43/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0149 - accuracy: 0.9947 - val_loss: 0.2549 - val_accuracy: 0.9413\n",
      "Epoch 44/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0056 - accuracy: 0.9979 - val_loss: 0.2123 - val_accuracy: 0.9541\n",
      "Epoch 45/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0148 - accuracy: 0.9964 - val_loss: 0.2154 - val_accuracy: 0.9509\n",
      "Epoch 00045: early stopping\n",
      "Melhor Accuracy de Treino:  0.9964166879653931\n",
      "Melhor Accuracy de Validação:  0.9593750238418579\n",
      "Treinando o modelo...\n",
      "Epoch 1/60\n",
      "375/375 [==============================] - 4s 9ms/step - loss: 0.7398 - accuracy: 0.7571 - val_loss: 1.3615 - val_accuracy: 0.6894\n",
      "Epoch 2/60\n",
      "375/375 [==============================] - 4s 9ms/step - loss: 0.2780 - accuracy: 0.9088 - val_loss: 0.7560 - val_accuracy: 0.7628\n",
      "Epoch 3/60\n",
      "375/375 [==============================] - 4s 9ms/step - loss: 0.1958 - accuracy: 0.9373 - val_loss: 0.4309 - val_accuracy: 0.8578\n",
      "Epoch 4/60\n",
      "375/375 [==============================] - 4s 9ms/step - loss: 0.1421 - accuracy: 0.9533 - val_loss: 0.2860 - val_accuracy: 0.9056\n",
      "Epoch 5/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.1142 - accuracy: 0.9610 - val_loss: 0.2738 - val_accuracy: 0.9103\n",
      "Epoch 6/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0899 - accuracy: 0.9720 - val_loss: 0.2151 - val_accuracy: 0.9291\n",
      "Epoch 7/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0778 - accuracy: 0.9736 - val_loss: 1.0004 - val_accuracy: 0.7641\n",
      "Epoch 8/60\n",
      "375/375 [==============================] - 4s 9ms/step - loss: 0.0822 - accuracy: 0.9720 - val_loss: 0.2421 - val_accuracy: 0.9244\n",
      "Epoch 9/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0540 - accuracy: 0.9827 - val_loss: 0.3069 - val_accuracy: 0.9159\n",
      "Epoch 10/60\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.0419 - accuracy: 0.9878 - val_loss: 0.2748 - val_accuracy: 0.9253\n",
      "Epoch 11/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0558 - accuracy: 0.9786 - val_loss: 0.2566 - val_accuracy: 0.9256\n",
      "Epoch 12/60\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.0297 - accuracy: 0.9899 - val_loss: 0.2369 - val_accuracy: 0.9312\n",
      "Epoch 13/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0398 - accuracy: 0.9870 - val_loss: 0.1884 - val_accuracy: 0.9453\n",
      "Epoch 14/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0252 - accuracy: 0.9917 - val_loss: 0.5038 - val_accuracy: 0.8853\n",
      "Epoch 15/60\n",
      "375/375 [==============================] - 4s 9ms/step - loss: 0.0236 - accuracy: 0.9925 - val_loss: 0.2070 - val_accuracy: 0.9447\n",
      "Epoch 16/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0233 - accuracy: 0.9923 - val_loss: 0.2685 - val_accuracy: 0.9312\n",
      "Epoch 17/60\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.0321 - accuracy: 0.9904 - val_loss: 0.3291 - val_accuracy: 0.9222\n",
      "Epoch 18/60\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 0.0296 - accuracy: 0.9904 - val_loss: 0.2988 - val_accuracy: 0.9281\n",
      "Epoch 19/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0235 - accuracy: 0.9919 - val_loss: 0.1648 - val_accuracy: 0.9581\n",
      "Epoch 20/60\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.0138 - accuracy: 0.9963 - val_loss: 0.4449 - val_accuracy: 0.8975\n",
      "Epoch 21/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0236 - accuracy: 0.9922 - val_loss: 0.2081 - val_accuracy: 0.9441\n",
      "Epoch 22/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0234 - accuracy: 0.9929 - val_loss: 0.3915 - val_accuracy: 0.9128\n",
      "Epoch 23/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0352 - accuracy: 0.9888 - val_loss: 0.3640 - val_accuracy: 0.9256\n",
      "Epoch 24/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0291 - accuracy: 0.9897 - val_loss: 0.2586 - val_accuracy: 0.9362\n",
      "Epoch 25/60\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.0127 - accuracy: 0.9956 - val_loss: 0.2976 - val_accuracy: 0.9337\n",
      "Epoch 26/60\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.0191 - accuracy: 0.9937 - val_loss: 0.2362 - val_accuracy: 0.9438\n",
      "Epoch 27/60\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.0143 - accuracy: 0.9945 - val_loss: 0.2178 - val_accuracy: 0.9453\n",
      "Epoch 28/60\n",
      "375/375 [==============================] - 4s 9ms/step - loss: 0.0095 - accuracy: 0.9976 - val_loss: 0.1849 - val_accuracy: 0.9538\n",
      "Epoch 29/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0111 - accuracy: 0.9964 - val_loss: 0.1621 - val_accuracy: 0.9616\n",
      "Epoch 30/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0049 - accuracy: 0.9986 - val_loss: 0.2021 - val_accuracy: 0.9516\n",
      "Epoch 31/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0195 - accuracy: 0.9937 - val_loss: 0.1839 - val_accuracy: 0.9534\n",
      "Epoch 32/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0172 - accuracy: 0.9933 - val_loss: 0.2237 - val_accuracy: 0.9444\n",
      "Epoch 33/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0198 - accuracy: 0.9940 - val_loss: 0.1837 - val_accuracy: 0.9563\n",
      "Epoch 34/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.0077 - accuracy: 0.9970 - val_loss: 0.1642 - val_accuracy: 0.9581\n",
      "Epoch 35/60\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 0.0047 - accuracy: 0.9986 - val_loss: 0.2366 - val_accuracy: 0.9444\n",
      "Epoch 36/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0198 - accuracy: 0.9935 - val_loss: 0.2428 - val_accuracy: 0.9450\n",
      "Epoch 37/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0150 - accuracy: 0.9954 - val_loss: 0.1884 - val_accuracy: 0.9603\n",
      "Epoch 38/60\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.0137 - accuracy: 0.9949 - val_loss: 0.2945 - val_accuracy: 0.9413\n",
      "Epoch 39/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0057 - accuracy: 0.9978 - val_loss: 0.1625 - val_accuracy: 0.9578\n",
      "Epoch 40/60\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.0040 - accuracy: 0.9991 - val_loss: 0.6607 - val_accuracy: 0.8888\n",
      "Epoch 41/60\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.0270 - accuracy: 0.9925 - val_loss: 0.2208 - val_accuracy: 0.9503\n",
      "Epoch 42/60\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.0090 - accuracy: 0.9977 - val_loss: 0.1887 - val_accuracy: 0.9575\n",
      "Epoch 43/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0083 - accuracy: 0.9971 - val_loss: 0.2647 - val_accuracy: 0.9422\n",
      "Epoch 44/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0112 - accuracy: 0.9971 - val_loss: 0.1727 - val_accuracy: 0.9569\n",
      "Epoch 45/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0101 - accuracy: 0.9967 - val_loss: 0.2096 - val_accuracy: 0.9494\n",
      "Epoch 46/60\n",
      "375/375 [==============================] - 4s 9ms/step - loss: 0.0106 - accuracy: 0.9967 - val_loss: 0.1633 - val_accuracy: 0.9588\n",
      "Epoch 47/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0053 - accuracy: 0.9985 - val_loss: 0.1514 - val_accuracy: 0.9606\n",
      "Epoch 48/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0088 - accuracy: 0.9975 - val_loss: 0.4169 - val_accuracy: 0.9219\n",
      "Epoch 49/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0127 - accuracy: 0.9964 - val_loss: 0.2038 - val_accuracy: 0.9522\n",
      "Epoch 50/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0043 - accuracy: 0.9985 - val_loss: 0.1985 - val_accuracy: 0.9553\n",
      "Epoch 51/60\n",
      "375/375 [==============================] - 4s 9ms/step - loss: 0.0073 - accuracy: 0.9978 - val_loss: 0.1937 - val_accuracy: 0.9528\n",
      "Epoch 52/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0036 - accuracy: 0.9991 - val_loss: 0.1660 - val_accuracy: 0.9634\n",
      "Epoch 53/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0038 - accuracy: 0.9986 - val_loss: 0.1662 - val_accuracy: 0.9581\n",
      "Epoch 54/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0107 - accuracy: 0.9967 - val_loss: 0.2659 - val_accuracy: 0.9438\n",
      "Epoch 55/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0124 - accuracy: 0.9961 - val_loss: 0.3138 - val_accuracy: 0.9287\n",
      "Epoch 56/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0053 - accuracy: 0.9978 - val_loss: 0.1519 - val_accuracy: 0.9625\n",
      "Epoch 57/60\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.0046 - accuracy: 0.9988 - val_loss: 0.1981 - val_accuracy: 0.9550\n",
      "Epoch 58/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0015 - accuracy: 0.9998 - val_loss: 0.2361 - val_accuracy: 0.9472\n",
      "Epoch 59/60\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.0055 - accuracy: 0.9981 - val_loss: 0.1973 - val_accuracy: 0.9550\n",
      "Epoch 60/60\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.0043 - accuracy: 0.9991 - val_loss: 0.4618 - val_accuracy: 0.9144\n",
      "Melhor Accuracy de Treino:  0.9979166388511658\n",
      "Melhor Accuracy de Validação:  0.9634374976158142\n",
      "Treinando o modelo...\n",
      "Epoch 1/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.7393 - accuracy: 0.7645 - val_loss: 0.4226 - val_accuracy: 0.8556\n",
      "Epoch 2/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.2800 - accuracy: 0.9101 - val_loss: 1.0951 - val_accuracy: 0.7078\n",
      "Epoch 3/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.1885 - accuracy: 0.9368 - val_loss: 0.6585 - val_accuracy: 0.8056\n",
      "Epoch 4/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.1823 - accuracy: 0.9365 - val_loss: 0.6362 - val_accuracy: 0.8078\n",
      "Epoch 5/60\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.1058 - accuracy: 0.9653 - val_loss: 0.2966 - val_accuracy: 0.9019\n",
      "Epoch 6/60\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.0714 - accuracy: 0.9773 - val_loss: 0.2531 - val_accuracy: 0.9219\n",
      "Epoch 7/60\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.0890 - accuracy: 0.9716 - val_loss: 0.1917 - val_accuracy: 0.9312\n",
      "Epoch 8/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0661 - accuracy: 0.9765 - val_loss: 0.2227 - val_accuracy: 0.9334\n",
      "Epoch 9/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0567 - accuracy: 0.9798 - val_loss: 0.1645 - val_accuracy: 0.9441\n",
      "Epoch 10/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0459 - accuracy: 0.9854 - val_loss: 0.2303 - val_accuracy: 0.9309\n",
      "Epoch 11/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0519 - accuracy: 0.9826 - val_loss: 0.2507 - val_accuracy: 0.9241\n",
      "Epoch 12/60\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.0316 - accuracy: 0.9885 - val_loss: 0.2778 - val_accuracy: 0.9184\n",
      "Epoch 13/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0292 - accuracy: 0.9896 - val_loss: 0.2382 - val_accuracy: 0.9381\n",
      "Epoch 14/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0365 - accuracy: 0.9888 - val_loss: 0.4903 - val_accuracy: 0.8844\n",
      "Epoch 15/60\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.0255 - accuracy: 0.9913 - val_loss: 0.2923 - val_accuracy: 0.9241\n",
      "Epoch 16/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0228 - accuracy: 0.9919 - val_loss: 0.1937 - val_accuracy: 0.9484\n",
      "Epoch 17/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0287 - accuracy: 0.9903 - val_loss: 0.1868 - val_accuracy: 0.9453\n",
      "Epoch 18/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0226 - accuracy: 0.9927 - val_loss: 0.2912 - val_accuracy: 0.9206\n",
      "Epoch 19/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0251 - accuracy: 0.9908 - val_loss: 0.2457 - val_accuracy: 0.9400\n",
      "Epoch 20/60\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.0240 - accuracy: 0.9915 - val_loss: 0.3197 - val_accuracy: 0.9300\n",
      "Epoch 21/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0132 - accuracy: 0.9964 - val_loss: 0.2837 - val_accuracy: 0.9278\n",
      "Epoch 22/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0295 - accuracy: 0.9901 - val_loss: 0.2921 - val_accuracy: 0.9212\n",
      "Epoch 23/60\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.0195 - accuracy: 0.9925 - val_loss: 0.2736 - val_accuracy: 0.9337\n",
      "Epoch 24/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0218 - accuracy: 0.9928 - val_loss: 0.2076 - val_accuracy: 0.9484\n",
      "Epoch 25/60\n",
      "375/375 [==============================] - 7s 17ms/step - loss: 0.0060 - accuracy: 0.9982 - val_loss: 0.1596 - val_accuracy: 0.9563\n",
      "Epoch 26/60\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.0078 - accuracy: 0.9978 - val_loss: 0.2628 - val_accuracy: 0.9322\n",
      "Epoch 27/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0246 - accuracy: 0.9914 - val_loss: 0.2248 - val_accuracy: 0.9391\n",
      "Epoch 28/60\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.0177 - accuracy: 0.9946 - val_loss: 0.2846 - val_accuracy: 0.9319\n",
      "Epoch 29/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.0135 - accuracy: 0.9946 - val_loss: 0.2415 - val_accuracy: 0.9434\n",
      "Epoch 30/60\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.0066 - accuracy: 0.9977 - val_loss: 0.2644 - val_accuracy: 0.9359\n",
      "Epoch 31/60\n",
      "375/375 [==============================] - 4s 9ms/step - loss: 0.0191 - accuracy: 0.9935 - val_loss: 0.2590 - val_accuracy: 0.9378\n",
      "Epoch 32/60\n",
      "375/375 [==============================] - 4s 9ms/step - loss: 0.0116 - accuracy: 0.9958 - val_loss: 0.2729 - val_accuracy: 0.9378\n",
      "Epoch 33/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0085 - accuracy: 0.9974 - val_loss: 0.2398 - val_accuracy: 0.9434\n",
      "Epoch 34/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0068 - accuracy: 0.9981 - val_loss: 0.2832 - val_accuracy: 0.9312\n",
      "Epoch 35/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0149 - accuracy: 0.9950 - val_loss: 0.1877 - val_accuracy: 0.9528\n",
      "Epoch 36/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0086 - accuracy: 0.9974 - val_loss: 0.1961 - val_accuracy: 0.9556\n",
      "Epoch 37/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0049 - accuracy: 0.9983 - val_loss: 0.1704 - val_accuracy: 0.9575\n",
      "Epoch 38/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0162 - accuracy: 0.9946 - val_loss: 0.1746 - val_accuracy: 0.9563\n",
      "Epoch 39/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0081 - accuracy: 0.9975 - val_loss: 0.3661 - val_accuracy: 0.9266\n",
      "Epoch 40/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0111 - accuracy: 0.9968 - val_loss: 0.2265 - val_accuracy: 0.9500\n",
      "Epoch 41/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0166 - accuracy: 0.9951 - val_loss: 0.2317 - val_accuracy: 0.9459\n",
      "Epoch 42/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0073 - accuracy: 0.9976 - val_loss: 0.4456 - val_accuracy: 0.9131\n",
      "Epoch 43/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0114 - accuracy: 0.9956 - val_loss: 0.2592 - val_accuracy: 0.9447\n",
      "Epoch 44/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0050 - accuracy: 0.9986 - val_loss: 0.3022 - val_accuracy: 0.9356\n",
      "Epoch 45/60\n",
      "375/375 [==============================] - 4s 9ms/step - loss: 0.0090 - accuracy: 0.9971 - val_loss: 0.2124 - val_accuracy: 0.9503\n",
      "Epoch 00045: early stopping\n",
      "Melhor Accuracy de Treino:  0.9972500205039978\n",
      "Melhor Accuracy de Validação:  0.9574999809265137\n",
      "Treinando o modelo...\n",
      "Epoch 1/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.7389 - accuracy: 0.7513 - val_loss: 2.4532 - val_accuracy: 0.5581\n",
      "Epoch 2/60\n",
      "375/375 [==============================] - 4s 9ms/step - loss: 0.2860 - accuracy: 0.9097 - val_loss: 0.6385 - val_accuracy: 0.8053\n",
      "Epoch 3/60\n",
      "375/375 [==============================] - 4s 9ms/step - loss: 0.1986 - accuracy: 0.9346 - val_loss: 0.4834 - val_accuracy: 0.8487\n",
      "Epoch 4/60\n",
      "375/375 [==============================] - 4s 9ms/step - loss: 0.1530 - accuracy: 0.9489 - val_loss: 1.1936 - val_accuracy: 0.7075\n",
      "Epoch 5/60\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.1398 - accuracy: 0.9541 - val_loss: 0.4844 - val_accuracy: 0.8659\n",
      "Epoch 6/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.0946 - accuracy: 0.9666 - val_loss: 0.2900 - val_accuracy: 0.9109\n",
      "Epoch 7/60\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 0.0738 - accuracy: 0.9765 - val_loss: 0.4383 - val_accuracy: 0.8841\n",
      "Epoch 8/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0694 - accuracy: 0.9768 - val_loss: 0.2549 - val_accuracy: 0.9244\n",
      "Epoch 9/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0604 - accuracy: 0.9788 - val_loss: 0.3882 - val_accuracy: 0.8863\n",
      "Epoch 10/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0498 - accuracy: 0.9815 - val_loss: 0.4162 - val_accuracy: 0.9022\n",
      "Epoch 11/60\n",
      "375/375 [==============================] - 4s 9ms/step - loss: 0.0470 - accuracy: 0.9839 - val_loss: 0.2860 - val_accuracy: 0.9219\n",
      "Epoch 12/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0338 - accuracy: 0.9868 - val_loss: 0.4539 - val_accuracy: 0.8816\n",
      "Epoch 13/60\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.0368 - accuracy: 0.9869 - val_loss: 0.2292 - val_accuracy: 0.9353\n",
      "Epoch 14/60\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.0277 - accuracy: 0.9915 - val_loss: 0.2619 - val_accuracy: 0.9206\n",
      "Epoch 15/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0289 - accuracy: 0.9900 - val_loss: 1.4826 - val_accuracy: 0.7775\n",
      "Epoch 16/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0450 - accuracy: 0.9854 - val_loss: 0.2310 - val_accuracy: 0.9400\n",
      "Epoch 17/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0402 - accuracy: 0.9861 - val_loss: 0.3597 - val_accuracy: 0.9184\n",
      "Epoch 18/60\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.0379 - accuracy: 0.9888 - val_loss: 0.3868 - val_accuracy: 0.9116\n",
      "Epoch 19/60\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.0398 - accuracy: 0.9890 - val_loss: 0.1649 - val_accuracy: 0.9531\n",
      "Epoch 20/60\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.0204 - accuracy: 0.9928 - val_loss: 0.3949 - val_accuracy: 0.9084\n",
      "Epoch 21/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0333 - accuracy: 0.9890 - val_loss: 0.2604 - val_accuracy: 0.9350\n",
      "Epoch 22/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0231 - accuracy: 0.9925 - val_loss: 0.2543 - val_accuracy: 0.9388\n",
      "Epoch 23/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0160 - accuracy: 0.9939 - val_loss: 0.2012 - val_accuracy: 0.9519\n",
      "Epoch 24/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0270 - accuracy: 0.9905 - val_loss: 0.2340 - val_accuracy: 0.9353\n",
      "Epoch 25/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0151 - accuracy: 0.9950 - val_loss: 0.2455 - val_accuracy: 0.9331\n",
      "Epoch 26/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0138 - accuracy: 0.9964 - val_loss: 0.2327 - val_accuracy: 0.9428\n",
      "Epoch 27/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0217 - accuracy: 0.9920 - val_loss: 0.3603 - val_accuracy: 0.9231\n",
      "Epoch 28/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0113 - accuracy: 0.9971 - val_loss: 0.1557 - val_accuracy: 0.9566\n",
      "Epoch 29/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0081 - accuracy: 0.9973 - val_loss: 0.2581 - val_accuracy: 0.9362\n",
      "Epoch 30/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0250 - accuracy: 0.9916 - val_loss: 0.2149 - val_accuracy: 0.9434\n",
      "Epoch 31/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0089 - accuracy: 0.9974 - val_loss: 0.1944 - val_accuracy: 0.9528\n",
      "Epoch 32/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0108 - accuracy: 0.9975 - val_loss: 0.1671 - val_accuracy: 0.9578\n",
      "Epoch 33/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0093 - accuracy: 0.9967 - val_loss: 0.4735 - val_accuracy: 0.9081\n",
      "Epoch 34/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0213 - accuracy: 0.9928 - val_loss: 0.2301 - val_accuracy: 0.9466\n",
      "Epoch 35/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0130 - accuracy: 0.9960 - val_loss: 0.2043 - val_accuracy: 0.9488\n",
      "Epoch 36/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0100 - accuracy: 0.9973 - val_loss: 0.7355 - val_accuracy: 0.8659\n",
      "Epoch 37/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0215 - accuracy: 0.9935 - val_loss: 0.2300 - val_accuracy: 0.9478\n",
      "Epoch 38/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0171 - accuracy: 0.9952 - val_loss: 0.2660 - val_accuracy: 0.9478\n",
      "Epoch 39/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0089 - accuracy: 0.9969 - val_loss: 0.4099 - val_accuracy: 0.9141\n",
      "Epoch 40/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0103 - accuracy: 0.9960 - val_loss: 0.2007 - val_accuracy: 0.9513\n",
      "Epoch 41/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0054 - accuracy: 0.9984 - val_loss: 0.1900 - val_accuracy: 0.9547\n",
      "Epoch 42/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0072 - accuracy: 0.9975 - val_loss: 0.2391 - val_accuracy: 0.9463\n",
      "Epoch 43/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0094 - accuracy: 0.9966 - val_loss: 0.2897 - val_accuracy: 0.9381\n",
      "Epoch 44/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0095 - accuracy: 0.9970 - val_loss: 0.2275 - val_accuracy: 0.9506\n",
      "Epoch 45/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0088 - accuracy: 0.9975 - val_loss: 0.2623 - val_accuracy: 0.9472\n",
      "Epoch 46/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0153 - accuracy: 0.9953 - val_loss: 0.2131 - val_accuracy: 0.9566\n",
      "Epoch 47/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0118 - accuracy: 0.9967 - val_loss: 0.2837 - val_accuracy: 0.9356\n",
      "Epoch 48/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0021 - accuracy: 0.9996 - val_loss: 0.2697 - val_accuracy: 0.9450\n",
      "Epoch 00048: early stopping\n",
      "Melhor Accuracy de Treino:  0.999750018119812\n",
      "Melhor Accuracy de Validação:  0.957812488079071\n",
      "Treinando o modelo...\n",
      "Epoch 1/60\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.7788 - accuracy: 0.7583 - val_loss: 4.4695 - val_accuracy: 0.3075\n",
      "Epoch 2/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.2980 - accuracy: 0.9045 - val_loss: 0.5077 - val_accuracy: 0.8422\n",
      "Epoch 3/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.1965 - accuracy: 0.9335 - val_loss: 3.9231 - val_accuracy: 0.4512\n",
      "Epoch 4/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.1378 - accuracy: 0.9553 - val_loss: 0.5276 - val_accuracy: 0.8541\n",
      "Epoch 5/60\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.1293 - accuracy: 0.9559 - val_loss: 0.2723 - val_accuracy: 0.9128\n",
      "Epoch 6/60\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.0988 - accuracy: 0.9647 - val_loss: 0.4255 - val_accuracy: 0.8703\n",
      "Epoch 7/60\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.0778 - accuracy: 0.9751 - val_loss: 0.6693 - val_accuracy: 0.8306\n",
      "Epoch 8/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0542 - accuracy: 0.9819 - val_loss: 0.4080 - val_accuracy: 0.8844\n",
      "Epoch 9/60\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.0485 - accuracy: 0.9836 - val_loss: 0.4477 - val_accuracy: 0.8803\n",
      "Epoch 10/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0554 - accuracy: 0.9816 - val_loss: 0.3559 - val_accuracy: 0.9038\n",
      "Epoch 11/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0376 - accuracy: 0.9868 - val_loss: 0.2278 - val_accuracy: 0.9372\n",
      "Epoch 12/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0420 - accuracy: 0.9846 - val_loss: 0.3095 - val_accuracy: 0.9134\n",
      "Epoch 13/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0288 - accuracy: 0.9901 - val_loss: 0.1575 - val_accuracy: 0.9556\n",
      "Epoch 14/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0249 - accuracy: 0.9926 - val_loss: 0.1894 - val_accuracy: 0.9481\n",
      "Epoch 15/60\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.0297 - accuracy: 0.9912 - val_loss: 0.1814 - val_accuracy: 0.9459\n",
      "Epoch 16/60\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.0345 - accuracy: 0.9888 - val_loss: 0.1755 - val_accuracy: 0.9472\n",
      "Epoch 17/60\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.0163 - accuracy: 0.9956 - val_loss: 0.2029 - val_accuracy: 0.9481\n",
      "Epoch 18/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0246 - accuracy: 0.9911 - val_loss: 0.3378 - val_accuracy: 0.9153\n",
      "Epoch 19/60\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.0272 - accuracy: 0.9910 - val_loss: 0.2434 - val_accuracy: 0.9388\n",
      "Epoch 20/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0184 - accuracy: 0.9940 - val_loss: 0.4495 - val_accuracy: 0.8984\n",
      "Epoch 21/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0237 - accuracy: 0.9918 - val_loss: 0.2331 - val_accuracy: 0.9444\n",
      "Epoch 22/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0172 - accuracy: 0.9945 - val_loss: 0.2549 - val_accuracy: 0.9375\n",
      "Epoch 23/60\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.0179 - accuracy: 0.9935 - val_loss: 0.2401 - val_accuracy: 0.9397\n",
      "Epoch 24/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0345 - accuracy: 0.9881 - val_loss: 0.3492 - val_accuracy: 0.9194\n",
      "Epoch 25/60\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.0200 - accuracy: 0.9930 - val_loss: 0.2933 - val_accuracy: 0.9306\n",
      "Epoch 26/60\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.0105 - accuracy: 0.9968 - val_loss: 0.1847 - val_accuracy: 0.9563\n",
      "Epoch 27/60\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.0228 - accuracy: 0.9931 - val_loss: 0.1720 - val_accuracy: 0.9531\n",
      "Epoch 28/60\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 0.0093 - accuracy: 0.9975 - val_loss: 0.3668 - val_accuracy: 0.9181\n",
      "Epoch 29/60\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.0142 - accuracy: 0.9956 - val_loss: 0.2707 - val_accuracy: 0.9450\n",
      "Epoch 30/60\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.0174 - accuracy: 0.9960 - val_loss: 0.4145 - val_accuracy: 0.9156\n",
      "Epoch 31/60\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.0168 - accuracy: 0.9942 - val_loss: 0.2783 - val_accuracy: 0.9444\n",
      "Epoch 32/60\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.0188 - accuracy: 0.9947 - val_loss: 0.2035 - val_accuracy: 0.9516\n",
      "Epoch 33/60\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.0092 - accuracy: 0.9969 - val_loss: 0.3224 - val_accuracy: 0.9281\n",
      "Epoch 00033: early stopping\n",
      "Melhor Accuracy de Treino:  0.9954166412353516\n",
      "Melhor Accuracy de Validação:  0.956250011920929\n",
      "Treinando o modelo...\n",
      "Epoch 1/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.7591 - accuracy: 0.7550 - val_loss: 0.6616 - val_accuracy: 0.8053\n",
      "Epoch 2/60\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 0.2795 - accuracy: 0.9119 - val_loss: 0.4418 - val_accuracy: 0.8475\n",
      "Epoch 3/60\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 0.2033 - accuracy: 0.9323 - val_loss: 0.4130 - val_accuracy: 0.8712\n",
      "Epoch 4/60\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.1460 - accuracy: 0.9528 - val_loss: 0.5189 - val_accuracy: 0.8347\n",
      "Epoch 5/60\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.1149 - accuracy: 0.9621 - val_loss: 0.4138 - val_accuracy: 0.8725\n",
      "Epoch 6/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.1056 - accuracy: 0.9613 - val_loss: 0.3311 - val_accuracy: 0.9000\n",
      "Epoch 7/60\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 0.0755 - accuracy: 0.9759 - val_loss: 0.3001 - val_accuracy: 0.9106\n",
      "Epoch 8/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.0596 - accuracy: 0.9801 - val_loss: 0.4677 - val_accuracy: 0.8778\n",
      "Epoch 9/60\n",
      "375/375 [==============================] - 8s 20ms/step - loss: 0.0618 - accuracy: 0.9780 - val_loss: 0.2739 - val_accuracy: 0.9225\n",
      "Epoch 10/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.0590 - accuracy: 0.9796 - val_loss: 0.2105 - val_accuracy: 0.9403\n",
      "Epoch 11/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.0602 - accuracy: 0.9798 - val_loss: 0.2777 - val_accuracy: 0.9187\n",
      "Epoch 12/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.0424 - accuracy: 0.9852 - val_loss: 0.2501 - val_accuracy: 0.9262\n",
      "Epoch 13/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.0266 - accuracy: 0.9921 - val_loss: 0.3427 - val_accuracy: 0.9122\n",
      "Epoch 14/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.0375 - accuracy: 0.9891 - val_loss: 0.1913 - val_accuracy: 0.9466\n",
      "Epoch 15/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.0261 - accuracy: 0.9922 - val_loss: 0.4424 - val_accuracy: 0.8866\n",
      "Epoch 16/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.0268 - accuracy: 0.9923 - val_loss: 0.1943 - val_accuracy: 0.9453\n",
      "Epoch 17/60\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.0265 - accuracy: 0.9925 - val_loss: 0.1712 - val_accuracy: 0.9509\n",
      "Epoch 18/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.0248 - accuracy: 0.9911 - val_loss: 0.2044 - val_accuracy: 0.9475\n",
      "Epoch 19/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.0257 - accuracy: 0.9919 - val_loss: 0.3576 - val_accuracy: 0.9147\n",
      "Epoch 20/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.0264 - accuracy: 0.9893 - val_loss: 0.3095 - val_accuracy: 0.9331\n",
      "Epoch 21/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.0137 - accuracy: 0.9965 - val_loss: 0.3915 - val_accuracy: 0.9069\n",
      "Epoch 22/60\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.0333 - accuracy: 0.9886 - val_loss: 0.3357 - val_accuracy: 0.9225\n",
      "Epoch 23/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.0201 - accuracy: 0.9932 - val_loss: 0.1543 - val_accuracy: 0.9550\n",
      "Epoch 24/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.0101 - accuracy: 0.9962 - val_loss: 0.2866 - val_accuracy: 0.9319\n",
      "Epoch 25/60\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.0225 - accuracy: 0.9924 - val_loss: 0.2740 - val_accuracy: 0.9325\n",
      "Epoch 26/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.0102 - accuracy: 0.9968 - val_loss: 0.2440 - val_accuracy: 0.9391\n",
      "Epoch 27/60\n",
      "375/375 [==============================] - 6s 17ms/step - loss: 0.0199 - accuracy: 0.9927 - val_loss: 0.6192 - val_accuracy: 0.8822\n",
      "Epoch 28/60\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 0.0233 - accuracy: 0.9919 - val_loss: 0.2102 - val_accuracy: 0.9478\n",
      "Epoch 29/60\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.0087 - accuracy: 0.9964 - val_loss: 0.1845 - val_accuracy: 0.9509\n",
      "Epoch 30/60\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.0196 - accuracy: 0.9940 - val_loss: 0.2304 - val_accuracy: 0.9416\n",
      "Epoch 31/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.0184 - accuracy: 0.9933 - val_loss: 0.1929 - val_accuracy: 0.9488\n",
      "Epoch 32/60\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.0060 - accuracy: 0.9982 - val_loss: 0.2566 - val_accuracy: 0.9422\n",
      "Epoch 33/60\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.0241 - accuracy: 0.9926 - val_loss: 0.2086 - val_accuracy: 0.9503\n",
      "Epoch 34/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.0081 - accuracy: 0.9976 - val_loss: 0.3061 - val_accuracy: 0.9291\n",
      "Epoch 35/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.0112 - accuracy: 0.9960 - val_loss: 0.2243 - val_accuracy: 0.9416\n",
      "Epoch 36/60\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.0074 - accuracy: 0.9974 - val_loss: 0.3648 - val_accuracy: 0.9316\n",
      "Epoch 37/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.0250 - accuracy: 0.9926 - val_loss: 0.2353 - val_accuracy: 0.9381\n",
      "Epoch 38/60\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.0086 - accuracy: 0.9971 - val_loss: 0.1553 - val_accuracy: 0.9600\n",
      "Epoch 39/60\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.0047 - accuracy: 0.9986 - val_loss: 0.2604 - val_accuracy: 0.9444\n",
      "Epoch 40/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.0072 - accuracy: 0.9975 - val_loss: 0.1693 - val_accuracy: 0.9566\n",
      "Epoch 41/60\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.0161 - accuracy: 0.9949 - val_loss: 0.2392 - val_accuracy: 0.9397\n",
      "Epoch 42/60\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.0097 - accuracy: 0.9975 - val_loss: 0.2460 - val_accuracy: 0.9466\n",
      "Epoch 43/60\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.0030 - accuracy: 0.9990 - val_loss: 0.2861 - val_accuracy: 0.9403\n",
      "Epoch 00043: early stopping\n",
      "Melhor Accuracy de Treino:  0.9988333582878113\n",
      "Melhor Accuracy de Validação:  0.9599999785423279\n",
      "Treinando o modelo...\n",
      "Epoch 1/60\n",
      "375/375 [==============================] - 6s 14ms/step - loss: 0.8021 - accuracy: 0.7503 - val_loss: 6.4987 - val_accuracy: 0.2647\n",
      "Epoch 2/60\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.3324 - accuracy: 0.9059 - val_loss: 2.1358 - val_accuracy: 0.4872\n",
      "Epoch 3/60\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.2073 - accuracy: 0.9361 - val_loss: 0.2594 - val_accuracy: 0.9172\n",
      "Epoch 4/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.1592 - accuracy: 0.9466 - val_loss: 0.3759 - val_accuracy: 0.8922\n",
      "Epoch 5/60\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.1190 - accuracy: 0.9611 - val_loss: 0.2857 - val_accuracy: 0.9078\n",
      "Epoch 6/60\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.0957 - accuracy: 0.9683 - val_loss: 0.4439 - val_accuracy: 0.8737\n",
      "Epoch 7/60\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.0776 - accuracy: 0.9755 - val_loss: 0.5416 - val_accuracy: 0.8587\n",
      "Epoch 8/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.0573 - accuracy: 0.9829 - val_loss: 0.1885 - val_accuracy: 0.9356\n",
      "Epoch 9/60\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.0616 - accuracy: 0.9796 - val_loss: 0.2258 - val_accuracy: 0.9306\n",
      "Epoch 10/60\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.0648 - accuracy: 0.9790 - val_loss: 0.2580 - val_accuracy: 0.9212\n",
      "Epoch 11/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.0313 - accuracy: 0.9909 - val_loss: 0.3007 - val_accuracy: 0.9175\n",
      "Epoch 12/60\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.0339 - accuracy: 0.9905 - val_loss: 0.2313 - val_accuracy: 0.9275\n",
      "Epoch 13/60\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.0468 - accuracy: 0.9836 - val_loss: 0.2634 - val_accuracy: 0.9272\n",
      "Epoch 14/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.0353 - accuracy: 0.9884 - val_loss: 0.1955 - val_accuracy: 0.9472\n",
      "Epoch 15/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.0362 - accuracy: 0.9875 - val_loss: 0.1717 - val_accuracy: 0.9488\n",
      "Epoch 16/60\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.0192 - accuracy: 0.9931 - val_loss: 0.4068 - val_accuracy: 0.8919\n",
      "Epoch 17/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.0270 - accuracy: 0.9918 - val_loss: 0.2036 - val_accuracy: 0.9478\n",
      "Epoch 18/60\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.0296 - accuracy: 0.9902 - val_loss: 0.2034 - val_accuracy: 0.9475\n",
      "Epoch 19/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.0228 - accuracy: 0.9922 - val_loss: 0.2067 - val_accuracy: 0.9475\n",
      "Epoch 20/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.0285 - accuracy: 0.9908 - val_loss: 0.1519 - val_accuracy: 0.9566\n",
      "Epoch 21/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.0122 - accuracy: 0.9961 - val_loss: 0.3583 - val_accuracy: 0.9225\n",
      "Epoch 22/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.0271 - accuracy: 0.9901 - val_loss: 0.2446 - val_accuracy: 0.9409\n",
      "Epoch 23/60\n",
      "375/375 [==============================] - 5s 15ms/step - loss: 0.0179 - accuracy: 0.9945 - val_loss: 0.3029 - val_accuracy: 0.9306\n",
      "Epoch 24/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.0263 - accuracy: 0.9919 - val_loss: 0.1802 - val_accuracy: 0.9500\n",
      "Epoch 25/60\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.0143 - accuracy: 0.9948 - val_loss: 0.1675 - val_accuracy: 0.9481\n",
      "Epoch 26/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.0080 - accuracy: 0.9972 - val_loss: 0.3922 - val_accuracy: 0.9181\n",
      "Epoch 27/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.0148 - accuracy: 0.9944 - val_loss: 0.2501 - val_accuracy: 0.9384\n",
      "Epoch 28/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.0119 - accuracy: 0.9966 - val_loss: 0.1559 - val_accuracy: 0.9575\n",
      "Epoch 29/60\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.0082 - accuracy: 0.9969 - val_loss: 0.1958 - val_accuracy: 0.9488\n",
      "Epoch 30/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.0147 - accuracy: 0.9961 - val_loss: 0.5422 - val_accuracy: 0.8881\n",
      "Epoch 31/60\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.0244 - accuracy: 0.9913 - val_loss: 0.1561 - val_accuracy: 0.9622\n",
      "Epoch 32/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.0030 - accuracy: 0.9992 - val_loss: 0.2151 - val_accuracy: 0.9466\n",
      "Epoch 33/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.0050 - accuracy: 0.9990 - val_loss: 0.3707 - val_accuracy: 0.9178\n",
      "Epoch 34/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.0133 - accuracy: 0.9961 - val_loss: 0.2189 - val_accuracy: 0.9463\n",
      "Epoch 35/60\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.0155 - accuracy: 0.9945 - val_loss: 0.2228 - val_accuracy: 0.9463\n",
      "Epoch 36/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.0075 - accuracy: 0.9981 - val_loss: 0.1638 - val_accuracy: 0.9566\n",
      "Epoch 37/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.0152 - accuracy: 0.9954 - val_loss: 0.2926 - val_accuracy: 0.9375\n",
      "Epoch 38/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.0076 - accuracy: 0.9980 - val_loss: 0.1729 - val_accuracy: 0.9594\n",
      "Epoch 39/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.0100 - accuracy: 0.9968 - val_loss: 0.2645 - val_accuracy: 0.9441\n",
      "Epoch 40/60\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.0104 - accuracy: 0.9972 - val_loss: 0.2052 - val_accuracy: 0.9497\n",
      "Epoch 00040: early stopping\n",
      "Melhor Accuracy de Treino:  0.9971666932106018\n",
      "Melhor Accuracy de Validação:  0.9621875286102295\n",
      "Treinando o modelo...\n",
      "Epoch 1/60\n",
      "375/375 [==============================] - 7s 15ms/step - loss: 0.7775 - accuracy: 0.7495 - val_loss: 0.5954 - val_accuracy: 0.8072\n",
      "Epoch 2/60\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 0.2840 - accuracy: 0.9124 - val_loss: 0.6289 - val_accuracy: 0.8144\n",
      "Epoch 3/60\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 0.1903 - accuracy: 0.9369 - val_loss: 0.3632 - val_accuracy: 0.8781\n",
      "Epoch 4/60\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 0.1475 - accuracy: 0.9508 - val_loss: 0.2279 - val_accuracy: 0.9225\n",
      "Epoch 5/60\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 0.1070 - accuracy: 0.9623 - val_loss: 0.2664 - val_accuracy: 0.9100\n",
      "Epoch 6/60\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 0.0937 - accuracy: 0.9686 - val_loss: 0.7183 - val_accuracy: 0.8087\n",
      "Epoch 7/60\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 0.0769 - accuracy: 0.9755 - val_loss: 0.2702 - val_accuracy: 0.9184\n",
      "Epoch 8/60\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 0.0628 - accuracy: 0.9783 - val_loss: 0.4265 - val_accuracy: 0.8775\n",
      "Epoch 9/60\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.0512 - accuracy: 0.9815 - val_loss: 0.4188 - val_accuracy: 0.9016\n",
      "Epoch 10/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.0414 - accuracy: 0.9860 - val_loss: 0.1936 - val_accuracy: 0.9388\n",
      "Epoch 11/60\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.0494 - accuracy: 0.9819 - val_loss: 0.3707 - val_accuracy: 0.9047\n",
      "Epoch 12/60\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.0318 - accuracy: 0.9904 - val_loss: 0.2802 - val_accuracy: 0.9306\n",
      "Epoch 13/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.0363 - accuracy: 0.9866 - val_loss: 0.2627 - val_accuracy: 0.9250\n",
      "Epoch 14/60\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.0234 - accuracy: 0.9930 - val_loss: 0.2636 - val_accuracy: 0.9331\n",
      "Epoch 15/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.0351 - accuracy: 0.9871 - val_loss: 0.5223 - val_accuracy: 0.8744\n",
      "Epoch 16/60\n",
      "375/375 [==============================] - 6s 15ms/step - loss: 0.0310 - accuracy: 0.9900 - val_loss: 0.4043 - val_accuracy: 0.9053\n",
      "Epoch 17/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.0273 - accuracy: 0.9912 - val_loss: 0.3001 - val_accuracy: 0.9209\n",
      "Epoch 18/60\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.0165 - accuracy: 0.9959 - val_loss: 0.2769 - val_accuracy: 0.9319\n",
      "Epoch 19/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.0245 - accuracy: 0.9916 - val_loss: 0.2492 - val_accuracy: 0.9306\n",
      "Epoch 20/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.0311 - accuracy: 0.9881 - val_loss: 0.1452 - val_accuracy: 0.9538\n",
      "Epoch 21/60\n",
      "375/375 [==============================] - 6s 17ms/step - loss: 0.0138 - accuracy: 0.9952 - val_loss: 0.2518 - val_accuracy: 0.9344\n",
      "Epoch 22/60\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 0.0205 - accuracy: 0.9939 - val_loss: 0.1992 - val_accuracy: 0.9475\n",
      "Epoch 23/60\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.0086 - accuracy: 0.9975 - val_loss: 0.3187 - val_accuracy: 0.9237\n",
      "Epoch 24/60\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 0.0156 - accuracy: 0.9958 - val_loss: 0.2742 - val_accuracy: 0.9381\n",
      "Epoch 25/60\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.0186 - accuracy: 0.9932 - val_loss: 0.2982 - val_accuracy: 0.9344\n",
      "Epoch 26/60\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.0190 - accuracy: 0.9935 - val_loss: 0.1551 - val_accuracy: 0.9588\n",
      "Epoch 27/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.0152 - accuracy: 0.9940 - val_loss: 0.1932 - val_accuracy: 0.9475\n",
      "Epoch 28/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.0157 - accuracy: 0.9951 - val_loss: 0.1837 - val_accuracy: 0.9541\n",
      "Epoch 29/60\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 0.0160 - accuracy: 0.9935 - val_loss: 0.4809 - val_accuracy: 0.8997\n",
      "Epoch 30/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.0172 - accuracy: 0.9938 - val_loss: 0.2067 - val_accuracy: 0.9472\n",
      "Epoch 31/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.0264 - accuracy: 0.9930 - val_loss: 0.1853 - val_accuracy: 0.9553\n",
      "Epoch 32/60\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.0090 - accuracy: 0.9978 - val_loss: 0.1806 - val_accuracy: 0.9619\n",
      "Epoch 33/60\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.0117 - accuracy: 0.9967 - val_loss: 0.2431 - val_accuracy: 0.9431\n",
      "Epoch 34/60\n",
      "375/375 [==============================] - 9s 23ms/step - loss: 0.0152 - accuracy: 0.9953 - val_loss: 0.1996 - val_accuracy: 0.9475\n",
      "Epoch 35/60\n",
      "375/375 [==============================] - 10s 26ms/step - loss: 0.0093 - accuracy: 0.9968 - val_loss: 0.2979 - val_accuracy: 0.9306\n",
      "Epoch 36/60\n",
      "375/375 [==============================] - 7s 20ms/step - loss: 0.0068 - accuracy: 0.9977 - val_loss: 0.1951 - val_accuracy: 0.9528\n",
      "Epoch 37/60\n",
      "375/375 [==============================] - 6s 15ms/step - loss: 0.0220 - accuracy: 0.9925 - val_loss: 0.2240 - val_accuracy: 0.9497\n",
      "Epoch 38/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.0081 - accuracy: 0.9976 - val_loss: 0.1739 - val_accuracy: 0.9578\n",
      "Epoch 39/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.0041 - accuracy: 0.9990 - val_loss: 0.3014 - val_accuracy: 0.9328\n",
      "Epoch 40/60\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.0227 - accuracy: 0.9922 - val_loss: 0.2185 - val_accuracy: 0.9506\n",
      "Epoch 00040: early stopping\n",
      "Melhor Accuracy de Treino:  0.9928333163261414\n",
      "Melhor Accuracy de Validação:  0.9618750214576721\n",
      "Treinando o modelo...\n",
      "Epoch 1/60\n",
      "375/375 [==============================] - 6s 15ms/step - loss: 0.7711 - accuracy: 0.7540 - val_loss: 0.4347 - val_accuracy: 0.8522\n",
      "Epoch 2/60\n",
      "375/375 [==============================] - 6s 17ms/step - loss: 0.2677 - accuracy: 0.9141 - val_loss: 0.8183 - val_accuracy: 0.8062\n",
      "Epoch 3/60\n",
      "375/375 [==============================] - 5s 15ms/step - loss: 0.1936 - accuracy: 0.9383 - val_loss: 0.9477 - val_accuracy: 0.8359\n",
      "Epoch 4/60\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 0.1373 - accuracy: 0.9537 - val_loss: 0.3608 - val_accuracy: 0.8841\n",
      "Epoch 5/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.1207 - accuracy: 0.9592 - val_loss: 0.2754 - val_accuracy: 0.9112\n",
      "Epoch 6/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.0925 - accuracy: 0.9689 - val_loss: 0.4875 - val_accuracy: 0.8603\n",
      "Epoch 7/60\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 0.0801 - accuracy: 0.9726 - val_loss: 0.3218 - val_accuracy: 0.9075\n",
      "Epoch 8/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.0655 - accuracy: 0.9798 - val_loss: 0.1924 - val_accuracy: 0.9347\n",
      "Epoch 9/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.0494 - accuracy: 0.9852 - val_loss: 0.2743 - val_accuracy: 0.9231\n",
      "Epoch 10/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.0447 - accuracy: 0.9856 - val_loss: 0.1751 - val_accuracy: 0.9403\n",
      "Epoch 11/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.0426 - accuracy: 0.9861 - val_loss: 0.3297 - val_accuracy: 0.9156\n",
      "Epoch 12/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.0376 - accuracy: 0.9878 - val_loss: 0.1909 - val_accuracy: 0.9409\n",
      "Epoch 13/60\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 0.0336 - accuracy: 0.9892 - val_loss: 0.2131 - val_accuracy: 0.9366\n",
      "Epoch 14/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.0368 - accuracy: 0.9892 - val_loss: 0.2424 - val_accuracy: 0.9350\n",
      "Epoch 15/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.0301 - accuracy: 0.9905 - val_loss: 0.2152 - val_accuracy: 0.9381\n",
      "Epoch 16/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.0293 - accuracy: 0.9902 - val_loss: 0.2348 - val_accuracy: 0.9347\n",
      "Epoch 17/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.0256 - accuracy: 0.9928 - val_loss: 0.2104 - val_accuracy: 0.9450\n",
      "Epoch 18/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.0217 - accuracy: 0.9918 - val_loss: 0.2545 - val_accuracy: 0.9322\n",
      "Epoch 19/60\n",
      "375/375 [==============================] - 6s 15ms/step - loss: 0.0319 - accuracy: 0.9894 - val_loss: 0.2010 - val_accuracy: 0.9459\n",
      "Epoch 20/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.0154 - accuracy: 0.9943 - val_loss: 0.2518 - val_accuracy: 0.9388\n",
      "Epoch 21/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.0139 - accuracy: 0.9959 - val_loss: 0.1623 - val_accuracy: 0.9547\n",
      "Epoch 22/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.0130 - accuracy: 0.9960 - val_loss: 0.2362 - val_accuracy: 0.9356\n",
      "Epoch 23/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.0236 - accuracy: 0.9918 - val_loss: 0.1860 - val_accuracy: 0.9528\n",
      "Epoch 24/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.0140 - accuracy: 0.9960 - val_loss: 0.2624 - val_accuracy: 0.9394\n",
      "Epoch 25/60\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.0151 - accuracy: 0.9959 - val_loss: 0.4466 - val_accuracy: 0.9072\n",
      "Epoch 26/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.0264 - accuracy: 0.9921 - val_loss: 0.2930 - val_accuracy: 0.9278\n",
      "Epoch 27/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.0193 - accuracy: 0.9938 - val_loss: 0.1722 - val_accuracy: 0.9506\n",
      "Epoch 28/60\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0172 - accuracy: 0.9945"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "2 root error(s) found.\n  (0) Resource exhausted:  OOM when allocating tensor with shape[32,64,64,3] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu\n\t [[{{node GatherV2}}]]\n\t [[IteratorGetNext]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n  (1) Resource exhausted:  OOM when allocating tensor with shape[32,64,64,3] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu\n\t [[{{node GatherV2}}]]\n\t [[IteratorGetNext]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[IteratorGetNext/_2]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n0 successful operations.\n0 derived errors ignored. [Op:__inference_test_function_1025995]\n\nFunction call stack:\ntest_function -> test_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 15\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTreinando o modelo...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     14\u001b[0m best_model \u001b[38;5;241m=\u001b[39m create_cnn_model(dropout_rate, best_learning_rate)\n\u001b[1;32m---> 15\u001b[0m best_model_history \u001b[38;5;241m=\u001b[39m \u001b[43mbest_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m60\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_validation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_validation\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_checkpoint\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m best_pso_train_accuracy \u001b[38;5;241m=\u001b[39m best_model_history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     18\u001b[0m best_pso_validation_accuracy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(best_model_history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf_38_gpu_ready_backup\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1131\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1117\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_frame \u001b[38;5;241m=\u001b[39m tf_inspect\u001b[38;5;241m.\u001b[39mcurrentframe()\n\u001b[0;32m   1118\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eval_data_handler \u001b[38;5;241m=\u001b[39m data_adapter\u001b[38;5;241m.\u001b[39mDataHandler(\n\u001b[0;32m   1119\u001b[0m       x\u001b[38;5;241m=\u001b[39mval_x,\n\u001b[0;32m   1120\u001b[0m       y\u001b[38;5;241m=\u001b[39mval_y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1129\u001b[0m       model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1130\u001b[0m       steps_per_execution\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_steps_per_execution)\n\u001b[1;32m-> 1131\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1132\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_x\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1133\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1134\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1135\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_batch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1136\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1137\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1138\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1139\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1140\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1141\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m   1142\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m name: val \u001b[38;5;28;01mfor\u001b[39;00m name, val \u001b[38;5;129;01min\u001b[39;00m val_logs\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[0;32m   1143\u001b[0m epoch_logs\u001b[38;5;241m.\u001b[39mupdate(val_logs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf_38_gpu_ready_backup\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1389\u001b[0m, in \u001b[0;36mModel.evaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[0;32m   1387\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trace\u001b[38;5;241m.\u001b[39mTrace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m, step_num\u001b[38;5;241m=\u001b[39mstep, _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m   1388\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_test_batch_begin(step)\n\u001b[1;32m-> 1389\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1390\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1391\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf_38_gpu_ready_backup\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:828\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    826\u001b[0m tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    827\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trace\u001b[38;5;241m.\u001b[39mTrace(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name) \u001b[38;5;28;01mas\u001b[39;00m tm:\n\u001b[1;32m--> 828\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    829\u001b[0m   compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_experimental_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    830\u001b[0m   new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf_38_gpu_ready_backup\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:862\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    859\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    860\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    861\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 862\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateful_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    863\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m    864\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    865\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf_38_gpu_ready_backup\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2942\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2939\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2940\u001b[0m   (graph_function,\n\u001b[0;32m   2941\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2942\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2943\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf_38_gpu_ready_backup\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1918\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1914\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1915\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1916\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1917\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1918\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1919\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1920\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1921\u001b[0m     args,\n\u001b[0;32m   1922\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1923\u001b[0m     executing_eagerly)\n\u001b[0;32m   1924\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf_38_gpu_ready_backup\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:555\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    553\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    554\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 555\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    556\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    557\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    558\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    559\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    560\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    561\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    562\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    563\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    564\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    567\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    568\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf_38_gpu_ready_backup\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:59\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     58\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 59\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     62\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: 2 root error(s) found.\n  (0) Resource exhausted:  OOM when allocating tensor with shape[32,64,64,3] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu\n\t [[{{node GatherV2}}]]\n\t [[IteratorGetNext]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n  (1) Resource exhausted:  OOM when allocating tensor with shape[32,64,64,3] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu\n\t [[{{node GatherV2}}]]\n\t [[IteratorGetNext]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[IteratorGetNext/_2]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n0 successful operations.\n0 derived errors ignored. [Op:__inference_test_function_1025995]\n\nFunction call stack:\ntest_function -> test_function\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "best_learning_rate = 0.001\n",
    "dropout_rate = 0.225\n",
    "\n",
    "val_accuracy_threshold = 0.965\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=20, min_delta=0.001, mode='min', verbose=1)\n",
    "model_checkpoint = ModelCheckpoint('best_model.h5', monitor='val_accuracy', mode='max', save_best_only=True, verbose=0)\n",
    "\n",
    "while True:\n",
    "    print(\"A trainar o modelo...\")\n",
    "    best_model = create_cnn_model(dropout_rate, best_learning_rate)\n",
    "    best_model_history = best_model.fit(x_train, y_train, epochs=60, batch_size=32, verbose=1, validation_data=(x_validation, y_validation),callbacks=[early_stopping, model_checkpoint])\n",
    "    \n",
    "    best_pso_train_accuracy = best_model_history.history['accuracy'][-1]\n",
    "    best_pso_validation_accuracy = max(best_model_history.history['val_accuracy'])\n",
    "\n",
    "\n",
    "    print(\"Melhor Accuracy de Treino: \", best_pso_train_accuracy)\n",
    "    print(\"Melhor Accuracy de Validação: \", best_pso_validation_accuracy)\n",
    "\n",
    "    if best_pso_validation_accuracy >= val_accuracy_threshold:\n",
    "        print(\"Atingiu a acurácia desejada no conjunto de validação.\")\n",
    "        break\n",
    "\n",
    "best_model = load_model('best_model.h5')\n",
    "\n",
    "loss_test, test_accuracy = best_model.evaluate(x_test, y_test, verbose=0)\n",
    "print(f\"Acurácia no Teste: {test_accuracy}, Loss: {loss_test}\")\n",
    "\n",
    "plt.plot(best_model_history.history['accuracy'], label='Treinamento')\n",
    "plt.plot(best_model_history.history['val_accuracy'], label='Validação')\n",
    "plt.xlabel('Épocas')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avaliando o modelo no conjunto de teste...\n",
      "Acurácia no Teste: 0.9612500071525574, Loss: 0.1891903281211853\n"
     ]
    }
   ],
   "source": [
    "print(\"Avaliando o modelo no conjunto de teste...\")\n",
    "loss_test, test_accuracy = best_model.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "print(f\"Acurácia no Teste: {test_accuracy}, Loss: {loss_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "# Formatar a acurácia para obter as três primeiras casas decimais\n",
    "formatted_accuracy = int(test_accuracy * 1000)\n",
    "# Gerar um GUID único para o nome do arquivo\n",
    "unique_filename = str(uuid.uuid4())\n",
    "# Salve o modelo com o nome de arquivo GUID e a acurácia formatada\n",
    "best_model.save(f'model_{formatted_accuracy}_{unique_filename}.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Binarize as etiquetas em um formato one-vs-all\n",
    "y_test_binarized = label_binarize(y_test, classes=np.arange(len(categories)))\n",
    "\n",
    "# Calcular a curva ROC e AUC para cada classe\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i, category in enumerate(categories):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test_binarized[:, i], y_pred_probs[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Plotar a curva ROC para cada classe\n",
    "plt.figure(figsize=(10, 8))\n",
    "for i, category in enumerate(categories):\n",
    "    plt.plot(fpr[i], tpr[i], lw=2, label=f'ROC curve of class {category} (area = {roc_auc[i]:.2f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic for Each Class')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
